{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"gpuClass":"standard","accelerator":"GPU"},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["이름: 전찬수\n","\n","학번: 20207155\n","\n"],"metadata":{"id":"cP08X2UGG_C0"}},{"cell_type":"markdown","source":["# Part 1: Saving and Loading Models\n","\n","* 이번 실습에서는 model을 저장하고 불러오는 방법에 대해서 학습니다\n","* 저장과 불러오기를 학습하는 것이 중요한 이유는, 많은 경우 사전에 training이 완료된 모델을 불러와서 사용할 수있어야 하기 때문입니다\n","\n"],"metadata":{"id":"CaVYYAPWG_C2"}},{"cell_type":"code","source":["%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","import matplotlib.pyplot as plt\n","\n","import torch\n","from torch import nn\n","from torch import optim\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms"],"metadata":{"tags":[],"trusted":true,"id":"MnzfKw5CG_C3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Daks2VdnH3gL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = 'cpu'\n","if torch.cuda.is_available():\n","    device = 'cuda'\n","\n","device"],"metadata":{"tags":[],"trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"gk7Gq86aG_C4","outputId":"427803fc-ebe0-445b-e460-3534ce1584d1","executionInfo":{"status":"ok","timestamp":1687083854075,"user_tz":-540,"elapsed":1158,"user":{"displayName":"전찬수","userId":"10602042438598641223"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["# Define a transform to normalize the data\n","transform = transforms.Compose([transforms.ToTensor(),\n","                                transforms.Normalize((0.5,), (0.5,))])\n","# Download and load the training data\n","trainset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n","\n","# Download and load the test data\n","testset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=False, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"],"metadata":{"tags":[],"trusted":true,"id":"4Osne2SaG_C5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"30c4026e-d139-471d-ec16-c7478b88398d","executionInfo":{"status":"ok","timestamp":1687083861909,"user_tz":-540,"elapsed":5404,"user":{"displayName":"전찬수","userId":"10602042438598641223"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 26421880/26421880 [00:01<00:00, 16016032.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz to F_MNIST_data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 29515/29515 [00:00<00:00, 271043.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to F_MNIST_data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4422102/4422102 [00:00<00:00, 5058635.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to F_MNIST_data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5148/5148 [00:00<00:00, 6852515.71it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to F_MNIST_data/FashionMNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["* 이미지 한개 샘플을 살펴봅니다 (이미 익숙한 그림입니다)"],"metadata":{"id":"w3DNxZqRG_C6"}},{"cell_type":"markdown","source":["# Train a network\n","\n","To make things more concise here, I moved the model architecture and training code from the last part to a file called `fc_model`. Importing this, we can easily create a fully-connected network with `fc_model.Network`, and train the network using `fc_model.train`. I'll use this model (once it's trained) to demonstrate how we can save and load models."],"metadata":{"id":"YiymtoiyG_C6"}},{"cell_type":"code","source":["from torch import nn, optim\n","import torch.nn.functional as F\n","\n","class Classifier(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.fc1 = nn.Linear(784, 256)\n","        self.fc2 = nn.Linear(256, 128)\n","        self.fc3 = nn.Linear(128, 64)\n","        self.fc4 = nn.Linear(64, 10)\n","\n","    def forward(self, x):\n","        x = x.view(x.shape[0], -1)\n","\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = F.relu(self.fc3(x))\n","        x = self.fc4(x)\n","\n","        return x\n","    ###############"],"metadata":{"tags":[],"trusted":true,"id":"U2y5tSliG_C7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create the network, define the criterion and optimizer\n","\n","model = Classifier()\n","model.to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.003)\n"],"metadata":{"tags":[],"trusted":true,"id":"4jIktfdaG_C7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 5\n","\n","for e in range(epochs):\n","    running_loss = 0\n","    for images, labels in trainloader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        log_ps = model(images)\n","        loss = criterion(log_ps, labels)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","\n","        running_loss += loss.item()\n","\n","    print(f\"Training loss: {running_loss/len(trainloader)}\")"],"metadata":{"tags":[],"trusted":true,"id":"Ezvz8hYOG_C8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7f97ccd9-ffea-418c-f212-30d0584d77ab","executionInfo":{"status":"ok","timestamp":1686577652872,"user_tz":-540,"elapsed":89408,"user":{"displayName":"전찬수","userId":"10602042438598641223"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training loss: 0.5136761216879654\n","Training loss: 0.39089719608013057\n","Training loss: 0.35305031539121673\n","Training loss: 0.3301233834168042\n","Training loss: 0.31696740193153494\n"]}]},{"cell_type":"markdown","source":["## Saving and loading networks\n","\n","* *저장하기*가 유용한 이유는 생각해보실 수 있죠? 우리가 training이 된 네트워크를 통해서 예측을 하고자 하는데, 매번 training을 할 수도, 이유도 없죠\n","* 대신에 training이 완료된 모델을 저장하고, 활용하고자 할때 불러와서 사용하면 유용하겠죠?\n","* Pytorch에서 우리가 training을 통해서 얻은 parameter들은 `state_dict`라는 형태로 자장됩니다\n","  * 즉 네트워크의 weight와 bias들이 각 layer 별로 저장됩니다. 아래 확인해보죠\n"],"metadata":{"id":"9IODpUCHG_C8"}},{"cell_type":"code","source":["print(\"Our model: \\n\\n\", model, '\\n')\n","print(\"The state dict keys: \\n\\n\", model.state_dict().keys())"],"metadata":{"trusted":true,"id":"oxLd-6rJG_C9","executionInfo":{"status":"ok","timestamp":1686577652873,"user_tz":-540,"elapsed":58,"user":{"displayName":"전찬수","userId":"10602042438598641223"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3dd33c93-1cdf-4ce0-f0b8-fd5dd357be6b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Our model: \n","\n"," Classifier(\n","  (fc1): Linear(in_features=784, out_features=256, bias=True)\n","  (fc2): Linear(in_features=256, out_features=128, bias=True)\n","  (fc3): Linear(in_features=128, out_features=64, bias=True)\n","  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",") \n","\n","The state dict keys: \n","\n"," odict_keys(['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias'])\n"]}]},{"cell_type":"code","source":["model.state_dict().keys()"],"metadata":{"id":"yTR4muCSTqw3","executionInfo":{"status":"ok","timestamp":1686577652873,"user_tz":-540,"elapsed":55,"user":{"displayName":"전찬수","userId":"10602042438598641223"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1268f3ee-088a-4175-a54f-dec770c9b981"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["odict_keys(['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias'])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["print(\"Our optimizer: \\n\\n\", optimizer, '\\n') #학습시점부터 재학습할때는 optimizer까지 저장해야한다\n","print(\"The state dict keys: \\n\\n\", optimizer.state_dict().keys())"],"metadata":{"trusted":true,"id":"wYFj09f_G_C9","executionInfo":{"status":"ok","timestamp":1686577652873,"user_tz":-540,"elapsed":53,"user":{"displayName":"전찬수","userId":"10602042438598641223"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0cef0481-8874-4adb-8312-25372503dc29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Our optimizer: \n","\n"," Adam (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    capturable: False\n","    differentiable: False\n","    eps: 1e-08\n","    foreach: None\n","    fused: None\n","    lr: 0.003\n","    maximize: False\n","    weight_decay: 0\n",") \n","\n","The state dict keys: \n","\n"," dict_keys(['state', 'param_groups'])\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"KDJMcF8hIleN"}},{"cell_type":"code","source":["optimizer.state_dict()"],"metadata":{"id":"vwr3HvLwbf83","executionInfo":{"status":"ok","timestamp":1686577652874,"user_tz":-540,"elapsed":52,"user":{"displayName":"전찬수","userId":"10602042438598641223"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"125cd54f-b2a1-43c7-f83d-258b30e1e504"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'state': {0: {'step': tensor(4690.),\n","   'exp_avg': tensor([[-4.5946e-04, -4.5939e-04, -4.5972e-04,  ..., -4.9390e-04,\n","            -4.6272e-04, -4.5935e-04],\n","           [-4.1300e-04, -4.1286e-04, -4.1318e-04,  ..., -4.1659e-04,\n","            -4.1487e-04, -4.1310e-04],\n","           [ 4.2755e-05,  4.2748e-05,  4.2748e-05,  ...,  4.6717e-05,\n","             4.2581e-05,  4.2781e-05],\n","           ...,\n","           [ 2.3426e-05,  2.3426e-05,  2.3426e-05,  ...,  2.3282e-05,\n","             2.3444e-05,  2.3431e-05],\n","           [ 9.8046e-05,  9.8046e-05,  9.8047e-05,  ...,  9.7638e-05,\n","             9.7794e-05,  9.8022e-05],\n","           [ 1.5705e-04,  1.5705e-04,  1.5724e-04,  ...,  1.5411e-04,\n","             1.5727e-04,  1.5717e-04]], device='cuda:0'),\n","   'exp_avg_sq': tensor([[5.9977e-06, 5.9926e-06, 5.9849e-06,  ..., 5.7150e-06, 5.8768e-06,\n","            5.9882e-06],\n","           [1.9716e-06, 1.9713e-06, 1.9692e-06,  ..., 1.9019e-06, 1.9571e-06,\n","            1.9696e-06],\n","           [1.4095e-06, 1.4088e-06, 1.4085e-06,  ..., 1.3727e-06, 1.3625e-06,\n","            1.4088e-06],\n","           ...,\n","           [5.4106e-07, 5.4096e-07, 5.4085e-07,  ..., 5.2647e-07, 5.3783e-07,\n","            5.4048e-07],\n","           [2.0120e-06, 2.0108e-06, 2.0022e-06,  ..., 1.9941e-06, 2.0061e-06,\n","            2.0111e-06],\n","           [2.9965e-06, 2.9961e-06, 2.9954e-06,  ..., 2.9434e-06, 2.9792e-06,\n","            2.9952e-06]], device='cuda:0')},\n","  1: {'step': tensor(4690.),\n","   'exp_avg': tensor([ 4.5946e-04,  4.1300e-04, -4.2755e-05, -1.8020e-04,  1.3787e-04,\n","            3.0067e-08,  5.6052e-45,  5.6052e-45,  2.3840e-17,  5.6052e-45,\n","            9.7061e-39, -5.2156e-04,  5.6052e-45,  9.2946e-06, -2.2226e-05,\n","            2.5629e-06, -2.4590e-04, -7.2376e-05,  2.3918e-28,  5.8579e-08,\n","           -9.8192e-05,  5.6052e-45, -3.2662e-04, -7.2910e-07,  5.6052e-45,\n","            1.5166e-04,  3.2409e-06,  2.0277e-04,  5.6052e-45,  1.5610e-07,\n","           -5.1407e-08,  4.2464e-04, -4.9995e-06,  5.6052e-45, -3.2812e-08,\n","            5.6052e-45,  2.9284e-04,  5.9670e-05, -6.4807e-05, -1.0477e-05,\n","            2.6184e-21,  6.9607e-08,  5.6052e-45, -2.3049e-08, -2.9643e-08,\n","           -5.5067e-04,  5.6052e-45,  1.3313e-09,  2.0727e-04, -5.2343e-09,\n","           -1.1179e-07,  1.4634e-05, -6.1297e-07,  9.1182e-09,  7.8884e-06,\n","           -1.0720e-03,  3.9612e-06,  2.1236e-05,  3.5712e-04,  1.4369e-05,\n","           -5.7887e-06, -4.0053e-06, -3.0477e-08,  1.1874e-06,  2.2712e-04,\n","           -1.6978e-06, -1.9460e-04,  5.6052e-45,  5.6052e-45, -6.6247e-22,\n","            1.0251e-06,  5.6052e-45, -1.3117e-06,  8.1163e-07,  6.4296e-07,\n","            8.4996e-07,  5.6052e-45,  9.7991e-39,  1.3358e-04, -4.9249e-11,\n","           -1.9730e-05,  5.6052e-45,  8.8942e-07,  5.6052e-45, -3.8372e-04,\n","            1.3668e-03,  6.9872e-13, -1.4110e-05, -2.5916e-11,  3.5461e-04,\n","           -1.7955e-07, -7.8231e-12,  6.0577e-16, -4.4143e-06, -6.2048e-04,\n","           -2.2286e-06, -3.5980e-11,  1.1168e-04,  5.6052e-45,  1.0006e-38,\n","            1.0829e-11,  8.3338e-12,  1.8637e-03,  5.6593e-09,  5.6052e-45,\n","           -2.6841e-28, -3.3729e-07,  5.6052e-45,  2.1005e-04,  1.0825e-08,\n","           -2.2971e-04, -3.4418e-04, -3.4545e-14, -5.1289e-14,  5.6052e-45,\n","            5.6052e-45, -7.2490e-16,  4.4896e-05, -5.3030e-06, -1.0358e-06,\n","            2.0804e-06,  5.6052e-45, -5.5908e-07, -2.4852e-06, -4.8135e-08,\n","            1.7271e-08, -4.2598e-11,  1.5739e-08, -1.3128e-28,  1.3603e-07,\n","            1.7330e-05,  3.6367e-06, -1.2397e-30, -6.1689e-05, -3.5313e-43,\n","           -5.3526e-07, -1.0641e-05, -1.3670e-04,  8.5983e-08,  5.6052e-45,\n","            9.8935e-06,  3.7967e-05, -2.9379e-20, -1.7377e-04, -4.5567e-04,\n","            3.0603e-04, -6.9145e-05, -1.7001e-04,  1.1996e-04, -3.6219e-08,\n","            7.8707e-04,  3.7496e-04,  2.7094e-27, -4.9229e-05,  5.6052e-45,\n","            5.6052e-45, -1.5690e-04, -5.2274e-05, -6.0345e-05, -3.4040e-04,\n","            2.9685e-28,  2.2638e-04,  5.6052e-45, -9.5349e-06,  4.3162e-28,\n","           -1.6960e-05, -3.3147e-11,  5.9562e-08, -3.8079e-04,  2.0515e-05,\n","            3.4078e-07,  1.2115e-26, -4.4027e-07, -1.7225e-40, -1.3289e-07,\n","           -3.8556e-19,  5.6052e-45,  1.1682e-03, -6.8049e-04, -1.8384e-09,\n","            4.3408e-06,  2.3562e-05, -1.6793e-04,  2.2818e-04,  5.6052e-45,\n","            5.6052e-45,  8.1046e-27,  1.8588e-05, -4.5111e-10,  1.3820e-23,\n","           -2.9579e-05, -3.1495e-04,  1.6535e-43,  9.9649e-07,  3.7641e-04,\n","            5.6052e-45, -2.7055e-06,  5.4170e-29, -6.6449e-07, -2.4204e-14,\n","            6.3645e-04, -1.4987e-04, -2.7365e-14,  4.0729e-13, -4.3092e-28,\n","           -2.7535e-28,  1.2714e-03, -4.5653e-04,  5.6052e-45,  1.5644e-04,\n","           -2.0511e-06,  2.2277e-04, -3.4615e-04,  1.0774e-08,  5.6052e-45,\n","           -5.8267e-04,  2.7475e-04,  5.6052e-45,  5.6052e-45, -1.7517e-04,\n","           -1.2924e-10,  1.1193e-04,  1.9421e-06, -1.7950e-06,  5.6052e-45,\n","            2.3895e-13,  5.7391e-16, -1.9209e-07,  5.3134e-05,  1.9603e-13,\n","            6.4180e-04,  1.7795e-06, -3.0114e-29,  5.6052e-45, -2.7311e-04,\n","            5.6052e-45,  5.6052e-45,  7.2132e-09,  5.6052e-45, -1.0150e-04,\n","           -5.6052e-45, -7.3782e-09,  3.4911e-04, -5.0050e-06,  3.6581e-05,\n","            3.3954e-05,  2.4065e-04,  2.5451e-05,  5.6052e-45, -3.1891e-15,\n","            5.6052e-45,  2.1791e-04,  1.7966e-29, -2.3426e-05, -9.8046e-05,\n","           -1.5705e-04], device='cuda:0'),\n","   'exp_avg_sq': tensor([5.9979e-06, 1.9716e-06, 1.4095e-06, 1.6062e-06, 4.4225e-06, 2.8363e-11,\n","           1.1885e-12, 3.3328e-12, 4.6509e-11, 2.1715e-11, 3.7965e-11, 2.8915e-06,\n","           3.5038e-11, 4.8262e-07, 2.7734e-06, 3.5130e-07, 3.8207e-07, 1.5280e-06,\n","           1.9797e-08, 3.7838e-08, 1.3664e-06, 1.9884e-11, 3.3262e-06, 2.5984e-08,\n","           4.8906e-10, 2.5114e-06, 8.2075e-08, 1.1904e-06, 6.1923e-11, 3.5234e-08,\n","           2.5317e-09, 1.7406e-06, 3.9014e-08, 2.5286e-11, 9.8833e-09, 4.2169e-13,\n","           8.4355e-07, 9.1406e-07, 3.5142e-07, 3.8388e-07, 4.1368e-09, 6.1700e-09,\n","           6.3032e-12, 6.2030e-08, 5.1194e-08, 1.2479e-05, 1.7003e-11, 4.6309e-07,\n","           2.3710e-06, 1.6964e-09, 5.6783e-08, 1.0656e-07, 4.1311e-08, 5.5045e-10,\n","           3.6636e-07, 1.1096e-05, 1.2780e-07, 2.4238e-08, 3.0177e-06, 6.7326e-07,\n","           5.3117e-07, 5.1410e-08, 6.2873e-10, 2.2439e-09, 8.4912e-08, 5.9769e-08,\n","           2.0649e-06, 2.1772e-13, 3.5427e-14, 1.0860e-08, 3.6946e-08, 2.3114e-12,\n","           1.0473e-06, 2.4926e-08, 6.1079e-09, 2.1095e-08, 5.2533e-11, 1.0547e-08,\n","           2.1630e-06, 1.4304e-08, 5.3126e-06, 4.2780e-11, 2.4778e-08, 3.7953e-13,\n","           1.5551e-06, 3.3906e-06, 6.1072e-09, 4.4319e-07, 5.0145e-08, 2.2986e-06,\n","           5.2576e-08, 1.8424e-08, 1.6101e-09, 1.2629e-07, 5.2044e-06, 2.2913e-08,\n","           2.0853e-08, 4.0933e-07, 2.5470e-11, 3.8680e-11, 3.1281e-09, 1.0455e-08,\n","           8.2668e-06, 2.5629e-09, 4.7273e-10, 5.6066e-10, 7.6719e-08, 8.1350e-13,\n","           2.1062e-06, 7.5435e-09, 9.7473e-07, 2.0808e-06, 9.0168e-11, 1.1519e-08,\n","           4.2357e-11, 1.0510e-11, 1.0322e-09, 8.6518e-08, 1.8065e-08, 1.3114e-07,\n","           7.6357e-08, 3.4043e-11, 3.0813e-09, 1.5008e-08, 3.5399e-08, 1.4236e-07,\n","           6.0138e-09, 8.4850e-09, 3.4629e-09, 5.1187e-09, 4.6881e-07, 1.3365e-07,\n","           4.2145e-11, 9.3748e-07, 7.9447e-09, 1.2857e-08, 4.0272e-08, 4.9836e-07,\n","           5.3346e-08, 6.2766e-13, 2.3488e-08, 1.6700e-06, 7.1438e-10, 1.0802e-06,\n","           1.4040e-06, 7.5716e-06, 2.9187e-07, 4.3667e-06, 1.8996e-06, 4.2346e-08,\n","           1.4855e-07, 2.0133e-07, 3.3893e-09, 1.0789e-06, 7.0405e-10, 3.6177e-11,\n","           1.7849e-06, 4.4609e-06, 6.0214e-07, 1.9304e-06, 2.8549e-10, 1.5679e-06,\n","           3.2577e-14, 8.9137e-07, 7.4650e-10, 1.1732e-06, 6.1615e-09, 4.9579e-09,\n","           4.5189e-07, 1.3996e-06, 2.2026e-08, 8.1027e-10, 4.2986e-11, 5.0703e-10,\n","           1.6475e-08, 3.0490e-10, 1.2699e-11, 5.0003e-06, 5.2307e-06, 9.6309e-09,\n","           3.3023e-09, 4.0466e-06, 9.2468e-07, 1.6747e-06, 2.0679e-12, 1.0008e-11,\n","           2.6291e-10, 7.4124e-08, 7.4779e-09, 4.7868e-12, 9.3111e-08, 2.2548e-06,\n","           8.1277e-10, 1.8664e-06, 1.0944e-06, 1.0708e-11, 3.0014e-07, 3.0938e-11,\n","           7.4677e-07, 2.0814e-09, 2.6516e-06, 1.0159e-05, 6.2450e-10, 1.0948e-09,\n","           9.5578e-11, 2.5920e-10, 3.6298e-06, 6.4569e-07, 1.2838e-11, 7.2255e-07,\n","           1.4198e-07, 6.6886e-07, 4.7728e-06, 4.9896e-09, 1.5314e-10, 5.2881e-06,\n","           7.2202e-06, 3.8670e-12, 6.5023e-11, 1.5372e-06, 4.2094e-09, 9.3847e-07,\n","           3.5431e-06, 4.5185e-08, 5.8793e-11, 1.0604e-08, 1.1150e-09, 1.4101e-08,\n","           3.9943e-06, 8.5640e-09, 7.6123e-06, 1.0558e-08, 1.8445e-09, 5.5955e-13,\n","           3.0646e-06, 2.9695e-10, 1.8575e-10, 5.1062e-08, 4.0664e-11, 3.8053e-06,\n","           9.6313e-11, 2.4239e-08, 5.3985e-06, 3.3781e-07, 3.5341e-07, 3.4721e-07,\n","           5.4328e-07, 7.4462e-07, 4.4024e-10, 4.5821e-09, 1.4143e-11, 6.6578e-07,\n","           3.4533e-09, 5.4106e-07, 2.0120e-06, 2.9965e-06], device='cuda:0')},\n","  2: {'step': tensor(4690.),\n","   'exp_avg': tensor([[-2.3959e-04,  6.5844e-05, -3.5661e-04,  ..., -3.6959e-38,\n","             1.1167e-04, -7.5967e-04],\n","           [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n","             5.6052e-45,  5.6052e-45],\n","           [ 1.4218e-08,  3.5484e-11, -2.8503e-06,  ...,  4.6717e-37,\n","             3.2243e-09, -9.5032e-09],\n","           ...,\n","           [ 3.0448e-03, -3.0965e-04, -4.7556e-04,  ...,  3.5119e-07,\n","             1.5947e-04,  2.7238e-04],\n","           [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n","             5.6052e-45,  5.6052e-45],\n","           [-3.4287e-06,  1.7940e-05, -1.2805e-07,  ...,  5.1819e-18,\n","             2.3303e-05,  2.6654e-05]], device='cuda:0'),\n","   'exp_avg_sq': tensor([[8.9784e-06, 1.2934e-06, 1.4419e-05,  ..., 5.0079e-06, 9.1441e-06,\n","            1.5979e-05],\n","           [7.8079e-15, 3.3083e-12, 2.7521e-12,  ..., 5.2686e-13, 3.1560e-13,\n","            2.1201e-14],\n","           [2.1073e-06, 4.6061e-08, 7.9008e-07,  ..., 1.0688e-07, 2.3382e-07,\n","            2.1890e-07],\n","           ...,\n","           [2.6385e-05, 1.3252e-05, 4.8699e-05,  ..., 2.7264e-05, 3.1219e-05,\n","            1.6538e-04],\n","           [9.6676e-09, 6.8800e-12, 1.1105e-09,  ..., 3.5848e-12, 1.1533e-09,\n","            6.9232e-11],\n","           [3.6245e-06, 6.3495e-08, 2.0212e-08,  ..., 8.4875e-08, 2.6652e-06,\n","            4.0772e-06]], device='cuda:0')},\n","  3: {'step': tensor(4690.),\n","   'exp_avg': tensor([-9.9349e-05,  5.6052e-45, -8.0048e-07, -6.9435e-05, -5.3513e-05,\n","           -8.7977e-05,  5.9942e-05,  7.6001e-07, -8.7329e-05, -2.3587e-06,\n","            2.7615e-04, -3.1613e-05, -9.3331e-05,  1.8925e-04, -2.9430e-06,\n","            9.8249e-17,  5.2961e-24, -1.8136e-04, -1.0663e-04,  1.9155e-04,\n","            5.6052e-45,  8.6997e-06,  3.9864e-04, -1.8177e-08, -4.7670e-05,\n","           -4.8539e-05,  2.8027e-10,  3.0812e-04,  2.5788e-04,  8.7827e-04,\n","            6.2599e-05, -2.7166e-06,  3.8587e-04, -1.3583e-05,  2.0144e-07,\n","           -1.6358e-04, -2.3043e-28, -3.4958e-05,  1.0069e-24,  2.6828e-04,\n","           -1.4995e-04, -4.7941e-05,  5.6052e-45,  5.7490e-05,  1.0035e-05,\n","           -2.6827e-04, -6.0914e-09,  1.7151e-18,  1.9231e-05,  5.6052e-45,\n","            2.7303e-04,  5.9555e-05, -3.3957e-04, -6.6853e-06, -1.9489e-09,\n","           -1.7159e-04, -1.9838e-05,  1.0074e-04,  5.6052e-45, -2.7488e-05,\n","            5.2263e-05, -2.2790e-04, -1.3305e-04, -1.8988e-05,  1.5218e-04,\n","            1.0854e-05,  1.4571e-04, -1.2566e-05, -5.9952e-05, -6.1287e-05,\n","            7.8955e-04,  2.6709e-04, -2.7998e-05,  1.5750e-07, -4.6182e-05,\n","           -6.4478e-04, -1.2933e-04, -2.2900e-05, -1.2666e-04,  1.2820e-04,\n","           -1.3630e-04,  9.6959e-30,  5.1673e-04,  3.1060e-04, -9.4018e-05,\n","           -4.1564e-05,  2.4904e-05, -2.1773e-04, -2.6282e-04,  4.1293e-05,\n","            1.6121e-04,  3.5327e-04, -4.4088e-05, -8.7888e-13, -1.9261e-05,\n","            8.8270e-05, -2.9150e-04,  1.8721e-05,  5.3528e-05, -1.3249e-04,\n","           -9.0904e-05,  9.2342e-05, -1.2871e-04, -1.7451e-04, -2.2203e-04,\n","           -6.0738e-09, -9.9825e-06,  2.9990e-04,  5.3288e-04, -3.1040e-05,\n","           -9.9140e-05,  2.1448e-04, -2.0029e-12, -5.4768e-15,  2.3646e-05,\n","            9.0499e-17,  3.0655e-04, -2.8350e-04, -4.6180e-06,  1.1384e-04,\n","           -4.1391e-05,  1.1972e-03,  3.5750e-04, -4.7551e-04, -3.7133e-05,\n","           -5.9657e-05,  5.6052e-45,  2.2673e-05], device='cuda:0'),\n","   'exp_avg_sq': tensor([1.1435e-06, 1.8777e-12, 4.1188e-08, 1.6581e-06, 2.2338e-07, 1.4222e-06,\n","           1.4849e-07, 1.2747e-07, 6.8046e-07, 8.4222e-08, 1.6201e-06, 2.2313e-06,\n","           3.9641e-06, 3.9285e-07, 6.0677e-07, 5.1292e-11, 1.9055e-11, 1.1594e-06,\n","           3.5017e-06, 2.3979e-07, 1.6017e-11, 8.4641e-07, 2.8460e-06, 1.4263e-08,\n","           1.6105e-07, 1.0877e-06, 7.6022e-08, 1.5532e-06, 4.2128e-07, 4.2131e-06,\n","           5.0412e-06, 1.0640e-07, 1.3513e-06, 5.1569e-07, 3.4411e-09, 2.7367e-06,\n","           2.7987e-10, 4.5455e-06, 2.4706e-10, 2.2943e-06, 6.8045e-07, 1.2707e-06,\n","           1.0061e-09, 3.1510e-06, 6.5532e-07, 7.0393e-07, 3.6915e-09, 3.3684e-09,\n","           7.3603e-07, 1.0490e-10, 2.0334e-06, 6.7373e-07, 6.6637e-07, 4.1378e-08,\n","           1.4418e-08, 6.1133e-07, 2.6124e-06, 3.8855e-07, 7.9031e-10, 1.0679e-06,\n","           2.3425e-07, 8.5835e-07, 3.2316e-07, 1.4693e-06, 2.1457e-06, 1.6610e-06,\n","           1.6973e-06, 5.7284e-08, 2.2446e-06, 1.4478e-08, 4.2896e-06, 1.6048e-06,\n","           2.6088e-07, 5.0963e-08, 1.1544e-06, 2.0384e-06, 8.6956e-07, 4.8424e-09,\n","           5.0379e-07, 4.6088e-07, 7.4688e-07, 1.2199e-08, 1.0586e-06, 3.6993e-06,\n","           9.8181e-08, 1.2869e-06, 1.9022e-06, 2.0499e-06, 1.9949e-06, 1.2515e-07,\n","           3.5181e-07, 3.4762e-06, 1.5197e-07, 1.4281e-10, 1.3588e-07, 3.2527e-06,\n","           1.4581e-06, 4.5083e-07, 2.2989e-07, 6.9945e-07, 1.2412e-06, 1.7410e-06,\n","           7.5556e-07, 2.8460e-07, 2.0172e-06, 2.7342e-08, 2.9501e-07, 2.0697e-06,\n","           4.6623e-06, 1.0311e-08, 3.9059e-07, 9.7606e-07, 4.3072e-09, 7.4917e-11,\n","           5.5400e-07, 7.2892e-09, 1.6296e-06, 2.1966e-06, 7.4672e-08, 1.7826e-07,\n","           5.9053e-07, 1.5526e-06, 1.2427e-06, 2.8430e-06, 3.4302e-07, 3.2940e-06,\n","           3.1996e-10, 1.5462e-07], device='cuda:0')},\n","  4: {'step': tensor(4690.),\n","   'exp_avg': tensor([[ 4.5820e-04, -5.6052e-45, -1.7669e-16,  ...,  1.1027e-03,\n","            -5.6052e-45, -1.8877e-07],\n","           [ 9.5107e-05, -5.6052e-45, -1.3860e-15,  ...,  2.8767e-03,\n","             5.6052e-45,  7.7276e-06],\n","           [ 9.2302e-37,  5.6052e-45, -5.6052e-45,  ...,  2.0621e-14,\n","            -5.6052e-45,  5.6052e-45],\n","           ...,\n","           [ 3.2182e-06, -5.6052e-45, -2.1431e-10,  ..., -1.1384e-03,\n","             5.6052e-45, -9.0094e-06],\n","           [-6.8693e-04,  0.0000e+00,  7.9415e-08,  ..., -7.3693e-04,\n","             5.6052e-45, -6.2375e-06],\n","           [-9.3346e-04, -5.6052e-45, -4.4654e-08,  ...,  1.2986e-03,\n","            -5.6052e-45, -6.6115e-06]], device='cuda:0'),\n","   'exp_avg_sq': tensor([[2.2688e-05, 9.8083e-15, 6.3078e-07,  ..., 8.1467e-05, 1.6711e-12,\n","            1.8771e-06],\n","           [1.7142e-05, 9.5574e-15, 1.2049e-06,  ..., 2.6675e-04, 3.8352e-13,\n","            2.1335e-06],\n","           [1.6316e-07, 5.0169e-15, 8.5211e-09,  ..., 4.7162e-07, 3.2712e-14,\n","            6.4999e-15],\n","           ...,\n","           [1.1958e-05, 4.2169e-13, 1.5189e-06,  ..., 1.1001e-04, 6.0155e-11,\n","            1.9127e-06],\n","           [3.3552e-05, 0.0000e+00, 1.5157e-06,  ..., 2.9451e-05, 2.8377e-11,\n","            8.6107e-07],\n","           [3.1753e-05, 1.2907e-13, 1.3591e-06,  ..., 3.2900e-05, 2.4783e-11,\n","            1.9176e-06]], device='cuda:0')},\n","  5: {'step': tensor(4690.),\n","   'exp_avg': tensor([ 2.6211e-04,  3.2109e-04,  2.7427e-15,  2.4533e-17,  4.5221e-05,\n","           -3.6549e-04,  5.1469e-04,  5.0664e-05,  5.8585e-04, -4.9767e-05,\n","            9.6778e-05,  5.6052e-45,  1.0247e-04, -2.7584e-05, -4.6167e-04,\n","           -4.5142e-06,  9.5003e-09, -2.2138e-04,  2.2999e-10, -2.8600e-04,\n","            1.1028e-06, -1.8818e-05,  4.8081e-05,  3.0891e-04,  5.9343e-05,\n","            9.8218e-08,  7.3712e-04,  4.1985e-04,  2.0796e-05, -1.6451e-04,\n","            2.3578e-11,  5.6052e-45, -4.4680e-04,  4.1372e-04, -4.1788e-06,\n","            5.7876e-04,  2.0651e-04,  1.1872e-03, -1.5488e-04,  1.2292e-04,\n","            2.2611e-04,  1.3270e-04,  9.5955e-06,  3.5434e-31,  5.6052e-45,\n","           -1.2963e-11, -8.3034e-04,  8.7519e-05, -3.8436e-05,  3.9302e-10,\n","            8.1079e-06,  5.6052e-45, -7.7853e-05,  5.5264e-05, -1.3796e-04,\n","            9.8374e-05,  1.8783e-07,  1.5421e-04,  1.0654e-04, -7.2487e-06,\n","            3.2639e-13,  1.0778e-04, -2.1045e-04,  1.4805e-03], device='cuda:0'),\n","   'exp_avg_sq': tensor([2.1695e-06, 1.6486e-05, 5.8983e-08, 7.0379e-10, 1.1274e-05, 8.1369e-06,\n","           9.8816e-06, 5.7023e-06, 1.5125e-05, 9.0423e-07, 1.4194e-06, 7.3973e-10,\n","           1.0480e-05, 8.4469e-08, 1.7822e-05, 1.9986e-07, 1.2637e-08, 1.3594e-06,\n","           1.2966e-09, 3.5300e-06, 1.3319e-07, 3.3094e-07, 2.8921e-05, 3.0094e-06,\n","           1.0090e-06, 7.8862e-08, 4.7327e-06, 1.8928e-06, 4.2056e-06, 2.4459e-06,\n","           5.8728e-08, 1.6404e-09, 6.9372e-06, 5.8374e-06, 2.6454e-07, 4.4650e-06,\n","           1.7294e-06, 6.2599e-06, 1.9858e-07, 1.9738e-06, 3.8973e-06, 2.9743e-06,\n","           3.2354e-08, 5.1075e-08, 3.9057e-09, 2.3671e-08, 9.1029e-06, 9.9189e-06,\n","           2.3602e-06, 2.8931e-08, 1.4832e-08, 8.2012e-10, 4.1001e-06, 1.8842e-07,\n","           1.7611e-06, 7.5745e-07, 9.9019e-08, 8.3656e-06, 5.3615e-06, 8.4199e-07,\n","           9.3114e-09, 1.6534e-05, 2.6345e-06, 1.1071e-05], device='cuda:0')},\n","  6: {'step': tensor(4690.),\n","   'exp_avg': tensor([[ 1.7457e-05,  2.9452e-03,  3.7070e-18,  7.8149e-20,  3.7393e-03,\n","             1.0379e-03,  6.2955e-03, -1.0516e-05,  2.0469e-03,  7.2177e-05,\n","            -1.4477e-05, -5.6052e-45,  3.7872e-02,  1.7597e-05,  5.6665e-03,\n","             6.6083e-05,  4.0648e-13,  5.1636e-04,  9.7895e-12, -2.7191e-03,\n","             3.7980e-05,  1.2935e-03,  7.7500e-02,  1.0796e-03,  1.5746e-04,\n","             2.8200e-07,  1.3297e-02,  8.4360e-04,  3.0652e-03,  1.3447e-03,\n","            -1.1702e-09,  5.6052e-45, -1.2902e-03,  1.5897e-03,  6.0685e-05,\n","             1.0734e-02,  8.8031e-06,  3.8740e-02,  5.2388e-03,  1.8206e-04,\n","             3.9944e-05,  7.9256e-04,  1.3033e-06,  2.0168e-30,  5.6052e-45,\n","             2.4189e-10,  1.6035e-03,  2.5734e-03, -7.1732e-04,  1.1430e-09,\n","             4.8478e-06,  5.6052e-45,  4.8083e-03,  6.9614e-05,  7.7818e-04,\n","             2.8136e-05,  8.7755e-10,  3.3113e-04,  2.5280e-02,  1.8942e-05,\n","            -2.3345e-11,  3.0813e-02,  3.8718e-04,  2.0292e-02],\n","           [ 3.7329e-06,  5.2124e-03,  2.6163e-19,  6.4754e-22,  1.8439e-03,\n","             4.3251e-05, -4.6973e-03, -1.6187e-03,  5.2277e-04,  4.3473e-06,\n","             1.0299e-04,  5.6052e-45, -7.2873e-03, -2.5806e-04, -1.1838e-02,\n","            -5.9541e-05,  5.3916e-16,  1.3666e-05,  2.2417e-12,  1.1488e-04,\n","             5.1184e-08,  1.3418e-07, -1.2070e-04, -2.5460e-03,  2.2380e-06,\n","             1.1709e-09, -1.1270e-03,  9.1363e-05,  6.5829e-04, -4.9257e-06,\n","             1.0449e-10,  5.6052e-45,  8.5730e-04,  1.1016e-03,  3.7375e-07,\n","             5.4223e-05,  1.7119e-06,  9.1638e-04,  1.0251e-05,  4.0827e-05,\n","             9.4108e-06,  2.2004e-04,  8.9596e-06,  1.8034e-32,  5.6052e-45,\n","            -9.2597e-10,  1.7587e-04,  5.4038e-04, -2.6209e-03, -1.9251e-09,\n","             2.8499e-08,  5.6052e-45, -4.5967e-04,  3.9886e-09,  1.9656e-05,\n","             1.4963e-03,  1.5409e-10, -2.9829e-03,  8.3408e-04,  2.8911e-05,\n","             3.7323e-16,  1.3179e-03,  2.0778e-06, -3.3404e-03],\n","           [ 6.4683e-06,  1.2170e-02,  5.7392e-19,  8.2224e-21, -3.5485e-03,\n","             8.5907e-03,  4.7106e-02,  4.0125e-05,  4.9512e-02,  9.2755e-06,\n","             1.2741e-05,  5.6052e-45, -8.1632e-03,  2.6065e-05,  2.8297e-03,\n","             2.2151e-05, -6.5880e-09,  1.5763e-03,  5.0362e-11, -1.2705e-03,\n","             1.3322e-06,  3.4158e-06, -2.3040e-02,  1.8214e-02, -1.3272e-04,\n","             9.0525e-08, -5.2559e-03,  2.2757e-04,  2.3925e-02, -2.0006e-04,\n","             7.7080e-11,  5.6052e-45, -1.5927e-04,  3.4435e-04,  1.3382e-06,\n","            -3.2548e-03,  2.4182e-06, -3.5081e-03,  1.4220e-04,  2.3176e-03,\n","             5.4362e-06,  5.1725e-04,  5.2802e-07, -6.1530e-31,  5.6052e-45,\n","             1.2258e-10, -6.3889e-04, -1.9094e-03,  8.3860e-05,  3.9334e-10,\n","             1.0169e-05,  5.6052e-45, -8.1832e-04, -1.4234e-06,  5.9417e-05,\n","             3.8964e-04,  2.3497e-10, -6.5887e-06, -1.1551e-02,  3.8468e-03,\n","             7.5350e-12,  4.0118e-03,  4.4642e-05,  2.6083e-02],\n","           [ 5.7026e-06, -1.8305e-02,  2.5361e-18,  4.7233e-21, -8.8873e-03,\n","             9.7464e-04,  4.7227e-03,  1.9473e-03,  6.5242e-04,  5.5438e-06,\n","             6.1297e-05,  5.6052e-45, -2.7675e-02,  2.8245e-04, -1.3719e-02,\n","             2.7250e-04,  2.8754e-16,  2.6520e-04,  9.5757e-12, -2.7412e-03,\n","             2.0737e-08,  7.5888e-06, -2.8130e-02,  2.1873e-03, -2.3129e-05,\n","             2.6286e-08, -1.1436e-02,  1.5868e-04,  4.4459e-04,  1.7115e-04,\n","             1.5154e-10,  5.6052e-45, -1.1020e-02, -5.9590e-03,  2.3767e-07,\n","             1.2534e-03,  2.4212e-06, -9.6728e-03,  4.8071e-05,  1.9216e-04,\n","             1.3019e-05, -1.1068e-03,  2.8650e-06, -1.2534e-30,  5.6052e-45,\n","             4.3004e-10,  1.7434e-03,  1.1827e-04,  4.3869e-03,  2.8668e-10,\n","             2.8427e-07,  5.6052e-45,  7.9802e-04,  5.3300e-08,  2.5790e-04,\n","            -1.5669e-03,  7.2594e-11,  3.0486e-03, -1.1627e-02,  2.0149e-05,\n","             9.3548e-13,  9.6937e-04,  9.1574e-06, -1.1925e-02],\n","           [ 6.6826e-06,  1.4636e-02,  4.0394e-18,  5.3577e-23,  1.2781e-02,\n","             1.0441e-03, -1.1912e-02,  1.8133e-05, -1.2833e-02,  2.5554e-06,\n","            -4.4799e-05,  5.6052e-45,  6.8691e-03,  8.6070e-05,  1.7092e-02,\n","             1.0381e-04,  5.7356e-11,  4.5666e-03, -1.4684e-10,  4.3340e-03,\n","             8.9651e-08,  7.2819e-06,  9.8352e-03,  3.6208e-03,  4.3002e-04,\n","             7.2895e-07,  3.6735e-03,  4.9268e-05, -8.2105e-03,  1.1738e-04,\n","             6.5832e-11,  5.6052e-45,  8.6383e-03,  5.8809e-03,  1.9136e-06,\n","             5.5588e-04,  1.6113e-06, -6.3048e-03, -1.9338e-05, -3.9028e-03,\n","             1.2546e-05, -7.1107e-05,  1.3022e-07,  4.2522e-32,  5.6052e-45,\n","             2.0220e-11,  2.4698e-02,  4.7453e-03,  6.8185e-05,  2.4798e-12,\n","             1.0594e-06,  5.6052e-45,  2.9297e-03,  7.8866e-07,  2.1100e-05,\n","            -4.3625e-04,  3.5650e-11,  1.5047e-05,  1.1502e-03, -4.2221e-03,\n","             6.3192e-13,  2.3782e-02,  2.8424e-05, -2.7747e-03],\n","           [-2.0711e-03,  7.8075e-05,  9.1136e-17, -9.9802e-17,  2.8151e-04,\n","            -1.0629e-03,  7.4099e-05,  7.9193e-03,  8.9513e-05,  5.6713e-03,\n","            -3.7979e-03,  5.6052e-45,  2.5241e-04, -2.1524e-05,  1.5711e-03,\n","             1.7523e-06,  4.9193e-17,  2.3628e-06,  2.2602e-12,  2.6568e-04,\n","             4.7585e-06,  3.7150e-06,  1.2591e-02,  9.2106e-03,  3.0806e-06,\n","             6.0409e-09,  3.3823e-05, -9.8109e-04, -4.5357e-04, -3.0295e-03,\n","             1.0060e-11,  5.6052e-45,  2.8138e-05,  1.1230e-02,  1.1222e-06,\n","             3.1638e-04, -2.6721e-03, -2.7072e-03,  1.6480e-06,  8.7438e-07,\n","            -6.9042e-03,  1.4102e-02, -4.3894e-04,  3.1896e-34,  5.6052e-45,\n","             1.4923e-14,  4.6774e-03,  1.6578e-05, -3.4787e-03,  2.3916e-15,\n","             1.3135e-09,  5.6052e-45,  5.0408e-06, -4.4512e-04, -3.6716e-04,\n","             6.9680e-07,  1.0822e-08, -3.0183e-04, -1.0849e-03,  1.0218e-08,\n","             1.0373e-16,  1.8164e-04,  1.1043e-02,  3.2901e-03],\n","           [ 2.3502e-05, -1.5679e-02,  1.4045e-17,  9.9587e-21,  1.6040e-03,\n","            -1.0764e-02, -4.1696e-02,  1.8881e-05, -3.9908e-02,  8.3656e-06,\n","             3.8158e-05,  5.6052e-45,  1.0385e-03, -1.6572e-04,  6.8178e-05,\n","            -4.2295e-04,  6.5280e-09, -6.9715e-03,  4.1655e-11,  2.2571e-03,\n","             4.1656e-06,  8.8392e-05, -3.5238e-02, -2.2681e-02, -3.4536e-04,\n","            -4.6018e-06,  1.3436e-03,  9.0790e-04, -1.9718e-02,  8.4065e-04,\n","             6.6909e-10,  5.6052e-45,  4.1566e-03, -3.5107e-03,  2.0493e-05,\n","            -4.1879e-03,  4.3867e-06, -1.9737e-02, -6.2863e-03,  1.3003e-03,\n","             4.7458e-05, -4.0602e-04,  1.3007e-07, -2.2458e-31,  5.6052e-45,\n","             1.0058e-10, -2.7721e-02, -6.3206e-03, -1.1601e-03,  5.5320e-11,\n","            -1.7150e-05, -5.6052e-45, -7.7526e-03,  6.8039e-07,  4.0401e-04,\n","             4.7251e-05,  1.9121e-10,  3.1019e-04, -9.9806e-05,  3.0332e-04,\n","             1.4227e-11, -6.0639e-02,  2.5213e-04, -2.8813e-02],\n","           [ 6.2529e-03,  1.3720e-03, -8.2138e-15,  2.0252e-17,  6.9045e-05,\n","             1.4477e-04,  1.8633e-05, -3.6590e-03,  2.2368e-05, -2.3228e-03,\n","             8.9399e-03,  5.6052e-45,  3.7249e-05,  3.3145e-07, -2.4047e-03,\n","             2.7816e-07,  1.1594e-18,  1.1833e-07,  8.1130e-13, -9.3097e-04,\n","             1.3827e-05,  7.6053e-07, -1.2149e-02, -2.8828e-03,  3.7376e-06,\n","             2.2154e-09,  4.1887e-06, -2.1856e-03,  2.2341e-06, -3.3188e-03,\n","             1.6425e-12,  5.6052e-45,  1.3107e-03, -1.1457e-02,  2.9044e-07,\n","            -9.1478e-04,  6.1360e-03,  7.2478e-06,  3.5479e-07,  4.0727e-07,\n","             1.4745e-02, -1.5382e-02,  1.0156e-05,  6.8409e-36,  5.6052e-45,\n","             9.8296e-16, -4.3679e-03,  1.4957e-06,  3.5108e-03,  1.0268e-17,\n","             3.0299e-11,  5.6052e-45,  7.9717e-06,  4.6688e-04,  1.5751e-03,\n","             1.3023e-07, -5.3845e-07,  5.9240e-03,  9.2294e-05,  6.1390e-09,\n","             2.4314e-18,  2.8186e-05, -1.2827e-02, -4.0020e-03],\n","           [ 1.1581e-04, -1.0765e-03,  1.3395e-17,  8.4381e-20, -7.9072e-03,\n","            -9.8074e-05,  7.3365e-05,  2.3854e-03, -1.1285e-04,  1.3654e-03,\n","             7.9186e-05,  5.6052e-45, -2.9805e-03,  1.1127e-05, -2.7969e-04,\n","             1.5295e-05,  2.1749e-12,  3.0552e-05,  2.8968e-11,  2.0860e-05,\n","            -4.4102e-05, -1.4053e-03, -4.4607e-04,  2.2702e-03, -9.7310e-05,\n","             3.4593e-06, -5.3776e-04,  3.7841e-04,  2.7926e-04,  2.5787e-03,\n","             8.4813e-11,  5.6052e-45, -1.2210e-03,  5.1940e-04, -8.6800e-05,\n","            -1.0496e-03,  1.7603e-04,  2.2278e-03,  8.6406e-04, -1.3235e-04,\n","             1.6147e-04,  1.8293e-04,  9.7723e-07,  1.5464e-32, -5.6052e-45,\n","             1.0653e-11, -1.9710e-04,  2.3029e-04,  5.4679e-05,  3.9554e-11,\n","             7.5989e-07,  5.6052e-45,  4.5597e-04,  4.3032e-04, -4.5106e-04,\n","             4.0933e-05,  4.1574e-07, -5.2217e-04, -3.0343e-03,  3.9596e-06,\n","             1.5962e-14, -4.9927e-04, -8.4505e-04,  8.1415e-04],\n","           [-4.3611e-03, -1.3537e-03,  8.0841e-15,  7.9363e-17,  2.4152e-05,\n","             8.9429e-05,  1.5242e-05, -7.0409e-03,  7.7209e-06, -4.8162e-03,\n","            -5.3771e-03,  5.6052e-45,  3.6833e-05,  2.1670e-05,  1.0140e-03,\n","             6.2531e-07,  1.0774e-17,  2.1739e-07,  1.1746e-12,  6.6921e-04,\n","            -1.8122e-05,  4.6510e-07, -8.0227e-04, -8.4729e-03,  1.9851e-06,\n","             5.3096e-09,  5.0460e-06,  5.0990e-04,  6.7935e-06,  1.5008e-03,\n","             5.6866e-12, -5.6052e-45, -1.3007e-03,  2.6068e-04,  3.4663e-07,\n","            -3.5063e-03, -3.6613e-03,  3.8832e-05,  2.8888e-07,  9.9648e-07,\n","            -8.1304e-03,  1.1510e-03,  4.1389e-04,  5.3782e-35,  5.6052e-45,\n","             7.6980e-15,  2.6724e-05,  4.2365e-06, -1.2725e-04,  2.8103e-16,\n","             1.2872e-10,  5.6052e-45,  2.5603e-05, -5.2179e-04, -2.2972e-03,\n","             1.1275e-07,  1.1033e-07, -5.8156e-03,  4.0708e-05,  1.4562e-08,\n","             2.2740e-17,  3.4765e-05,  1.9047e-03,  3.7539e-04]], device='cuda:0'),\n","   'exp_avg_sq': tensor([[4.1646e-06, 4.2394e-04, 6.7019e-07, 7.7390e-10, 5.3036e-04, 1.8190e-03,\n","            2.4376e-03, 5.0715e-05, 8.1697e-04, 4.9244e-06, 5.2578e-06, 6.9508e-11,\n","            3.0451e-02, 8.8139e-06, 5.9589e-03, 8.8626e-05, 1.7950e-06, 2.3118e-05,\n","            2.3357e-12, 5.9087e-04, 2.4296e-05, 1.6732e-05, 4.5811e-02, 3.0488e-05,\n","            3.5059e-05, 1.2649e-07, 6.9377e-03, 2.8511e-04, 2.4879e-04, 6.8468e-04,\n","            9.1584e-06, 8.8642e-13, 3.7921e-04, 5.3674e-04, 3.5109e-05, 8.0358e-04,\n","            5.4912e-06, 8.6094e-03, 7.9717e-05, 2.2044e-05, 9.4080e-06, 4.9689e-05,\n","            4.9975e-07, 1.1061e-05, 1.0955e-08, 4.9067e-06, 2.0844e-04, 5.3260e-03,\n","            3.1342e-04, 5.7869e-06, 5.2726e-08, 7.7234e-11, 2.2431e-03, 9.0977e-06,\n","            4.0842e-06, 3.2788e-04, 5.3629e-07, 1.0913e-04, 1.2184e-02, 2.2192e-05,\n","            4.5308e-06, 1.3188e-02, 1.9281e-04, 8.2218e-03],\n","           [5.8558e-07, 8.8883e-04, 1.8348e-05, 7.7366e-11, 1.0976e-04, 3.1255e-05,\n","            1.0515e-03, 1.3264e-04, 2.2267e-05, 1.8085e-06, 2.7338e-05, 1.2778e-12,\n","            2.4101e-03, 8.5274e-06, 5.7517e-03, 6.0747e-05, 1.2427e-07, 6.1560e-07,\n","            1.2198e-13, 8.3452e-06, 1.3938e-08, 2.3150e-06, 8.4666e-05, 8.7102e-05,\n","            9.0074e-05, 5.4968e-09, 3.1586e-04, 4.5652e-05, 4.4133e-05, 1.8726e-05,\n","            2.9745e-07, 5.1615e-13, 1.4756e-04, 1.7484e-04, 1.8370e-06, 4.3688e-05,\n","            4.2779e-06, 8.4592e-04, 8.9594e-06, 1.5249e-06, 4.0564e-07, 1.2185e-05,\n","            4.4589e-08, 5.9212e-08, 1.4942e-09, 1.0370e-05, 5.2906e-06, 1.5599e-04,\n","            1.2825e-03, 1.1253e-05, 2.5064e-10, 6.4571e-12, 4.0000e-05, 5.8595e-07,\n","            2.2104e-06, 3.2651e-04, 1.5616e-07, 4.4591e-04, 1.3610e-04, 2.4369e-05,\n","            9.6695e-09, 1.0661e-04, 1.0292e-06, 1.7621e-03],\n","           [6.4801e-07, 1.7479e-02, 6.7852e-07, 3.7535e-09, 5.9771e-03, 3.0938e-03,\n","            1.4928e-02, 1.6547e-05, 1.1895e-02, 2.7390e-06, 4.8351e-07, 2.1597e-08,\n","            1.0274e-03, 1.8721e-05, 1.9070e-03, 3.5143e-05, 2.7220e-06, 3.2250e-04,\n","            5.1781e-10, 1.1642e-03, 1.3377e-06, 1.7230e-05, 6.8453e-03, 5.5034e-05,\n","            4.8631e-04, 3.8980e-07, 8.9671e-04, 1.2829e-04, 7.4175e-03, 1.8872e-04,\n","            3.0450e-06, 4.0417e-12, 1.5019e-03, 1.0710e-03, 1.3015e-06, 5.5536e-05,\n","            5.2755e-07, 8.7277e-04, 5.3983e-05, 1.9709e-03, 1.0895e-06, 1.0446e-04,\n","            3.0519e-09, 5.8935e-07, 3.1054e-08, 1.9167e-07, 7.7812e-03, 7.9925e-04,\n","            4.1470e-05, 4.6036e-06, 3.8304e-07, 3.9409e-11, 3.4878e-04, 5.4547e-06,\n","            2.7682e-06, 5.1862e-05, 2.7919e-07, 2.1027e-05, 1.4838e-03, 8.9107e-04,\n","            4.0626e-06, 5.1215e-02, 3.8256e-05, 9.4898e-03],\n","           [6.4255e-07, 7.8077e-03, 2.8036e-07, 4.5573e-11, 1.9830e-03, 1.5957e-04,\n","            2.5098e-03, 1.3207e-04, 2.3185e-04, 7.3341e-07, 3.2703e-05, 1.7472e-11,\n","            1.3916e-02, 8.9790e-06, 2.2754e-02, 6.0471e-05, 4.7054e-07, 1.1505e-05,\n","            2.2261e-12, 7.4025e-04, 7.8833e-08, 7.8792e-06, 3.9083e-03, 8.1911e-05,\n","            4.8138e-05, 9.1633e-07, 3.3501e-03, 3.7605e-05, 1.7561e-05, 3.7520e-05,\n","            1.3554e-06, 3.6205e-12, 4.7842e-03, 1.5501e-03, 4.7380e-07, 4.8111e-05,\n","            6.4034e-06, 1.1555e-03, 3.9119e-06, 7.1046e-05, 1.7472e-06, 2.9914e-05,\n","            1.5043e-07, 5.1714e-07, 3.5156e-10, 6.1430e-06, 8.7850e-05, 1.6025e-03,\n","            8.6297e-04, 5.7991e-06, 7.0273e-09, 6.1648e-12, 2.0457e-04, 2.6903e-06,\n","            3.4044e-06, 7.0024e-04, 5.6408e-07, 4.8488e-04, 3.1577e-03, 7.8682e-06,\n","            3.9889e-10, 2.4513e-03, 1.7805e-05, 5.3801e-03],\n","           [1.4269e-06, 3.6771e-02, 9.8892e-07, 2.0051e-11, 8.7265e-03, 8.5060e-04,\n","            6.3232e-03, 6.8775e-06, 5.2362e-03, 2.9835e-07, 2.9288e-06, 6.8178e-10,\n","            6.2195e-04, 3.3733e-05, 9.9444e-03, 1.6501e-05, 9.1654e-07, 9.2091e-04,\n","            5.2817e-10, 1.8206e-03, 8.7164e-07, 4.8784e-05, 2.8822e-03, 2.5587e-05,\n","            2.3262e-04, 1.8991e-06, 4.4736e-04, 3.3568e-05, 5.8732e-03, 3.2457e-05,\n","            1.5998e-06, 6.3356e-11, 5.7092e-03, 1.2808e-03, 4.1765e-06, 1.6411e-04,\n","            1.1432e-06, 2.2348e-04, 6.6582e-05, 2.1943e-03, 8.4884e-07, 7.4100e-05,\n","            3.5835e-08, 9.4778e-07, 3.7182e-09, 1.8408e-06, 1.1706e-02, 3.0384e-03,\n","            1.7958e-04, 6.6098e-06, 4.9467e-07, 1.5446e-11, 2.0839e-03, 5.5780e-06,\n","            1.4193e-07, 4.0094e-05, 5.6041e-08, 2.7598e-05, 1.6959e-04, 9.5919e-04,\n","            2.9439e-08, 5.2284e-02, 5.1320e-05, 5.7261e-03],\n","           [4.1625e-04, 4.2051e-05, 5.4700e-09, 1.4879e-09, 1.0421e-04, 1.2794e-04,\n","            1.5600e-05, 8.6954e-03, 1.4465e-05, 2.0704e-03, 4.8886e-04, 1.1163e-09,\n","            1.4341e-05, 5.1021e-07, 2.6718e-04, 1.9896e-07, 5.2946e-09, 8.4582e-08,\n","            1.2403e-13, 4.5505e-05, 3.0362e-05, 1.1088e-05, 1.7325e-03, 8.0692e-03,\n","            7.2519e-06, 7.6417e-07, 7.4973e-06, 2.3673e-04, 4.1086e-06, 2.6119e-03,\n","            1.3405e-06, 4.0362e-13, 1.0976e-04, 8.1257e-04, 2.1087e-06, 3.1324e-03,\n","            1.9419e-03, 1.1094e-05, 2.5086e-06, 1.9946e-10, 1.7661e-03, 6.9780e-03,\n","            1.0980e-05, 1.7233e-10, 9.1616e-09, 1.6336e-07, 1.3581e-04, 1.3638e-05,\n","            2.4088e-04, 9.6812e-07, 2.4155e-08, 2.4116e-12, 1.6417e-04, 8.0564e-05,\n","            2.5517e-03, 6.6211e-06, 1.5982e-05, 2.2764e-03, 1.1054e-04, 1.1469e-06,\n","            2.2405e-10, 2.7225e-05, 4.9308e-03, 1.9209e-04],\n","           [5.6466e-06, 1.5338e-02, 1.4158e-05, 7.2859e-09, 1.4090e-03, 4.5535e-03,\n","            1.0595e-02, 1.7125e-05, 5.9509e-03, 3.7905e-06, 2.1735e-06, 7.7249e-09,\n","            2.3187e-02, 1.7052e-05, 5.4974e-03, 5.9746e-05, 2.5599e-06, 1.0815e-03,\n","            3.9910e-10, 3.2178e-03, 4.6206e-06, 8.5360e-06, 5.2850e-02, 6.4518e-05,\n","            2.7325e-04, 3.4358e-07, 4.9997e-03, 3.1662e-04, 1.9239e-03, 4.6526e-04,\n","            7.1790e-06, 3.6018e-11, 2.0726e-03, 6.6570e-04, 3.1052e-06, 3.0850e-04,\n","            1.3881e-06, 6.9630e-03, 9.7982e-05, 1.2355e-04, 1.0815e-05, 5.4414e-05,\n","            2.7384e-07, 1.1277e-05, 2.9957e-08, 8.7431e-07, 9.7215e-03, 9.0832e-03,\n","            1.0737e-04, 2.1133e-06, 4.5062e-07, 5.4854e-10, 4.0990e-03, 9.1126e-06,\n","            7.4580e-07, 1.4151e-04, 6.2107e-07, 4.5571e-05, 1.0556e-02, 1.0622e-04,\n","            7.1205e-07, 4.7365e-02, 1.0327e-04, 6.7154e-03],\n","           [7.1182e-03, 4.4806e-05, 5.9979e-06, 1.7806e-11, 5.0128e-05, 1.3013e-04,\n","            6.9394e-06, 1.7313e-03, 5.6896e-05, 2.7356e-03, 2.7371e-03, 9.1607e-12,\n","            3.1358e-06, 6.1193e-07, 1.0403e-04, 4.7643e-07, 2.4653e-10, 6.9675e-10,\n","            2.6109e-14, 3.5318e-04, 4.6047e-05, 6.2555e-06, 5.5248e-04, 6.2518e-03,\n","            9.5733e-05, 2.6446e-06, 1.0854e-06, 6.6910e-05, 1.5252e-07, 2.2405e-03,\n","            1.0586e-06, 2.3185e-10, 2.9950e-04, 5.9420e-04, 3.5322e-07, 5.5787e-04,\n","            2.8648e-03, 2.8777e-07, 3.9547e-06, 1.0861e-09, 1.6521e-02, 6.4159e-03,\n","            1.0804e-06, 1.0219e-10, 3.4062e-08, 1.0607e-07, 4.2221e-05, 2.9126e-06,\n","            1.1612e-03, 1.9817e-06, 1.0054e-08, 6.4135e-12, 4.1766e-05, 1.3015e-04,\n","            4.3025e-03, 2.2958e-06, 2.7353e-05, 4.8835e-03, 7.8257e-05, 1.1254e-06,\n","            7.0621e-11, 1.2740e-06, 4.3960e-03, 1.3523e-04],\n","           [9.8865e-05, 2.0015e-04, 5.3322e-06, 1.8943e-10, 1.2876e-03, 1.8928e-03,\n","            2.1790e-04, 3.3840e-05, 1.4497e-04, 4.8497e-05, 3.5332e-06, 3.2098e-09,\n","            2.3242e-04, 3.2144e-06, 2.0052e-03, 2.0971e-06, 3.9078e-07, 3.9867e-06,\n","            2.0389e-11, 9.5952e-05, 2.8494e-05, 6.8358e-05, 6.5832e-04, 8.2147e-05,\n","            1.5469e-05, 6.7815e-07, 3.4002e-05, 4.6589e-04, 6.1098e-05, 1.2986e-03,\n","            8.3070e-08, 1.7857e-11, 1.7813e-04, 2.7292e-04, 3.7460e-05, 1.5096e-03,\n","            1.0621e-04, 1.3994e-04, 2.8869e-05, 7.2566e-06, 9.6796e-05, 6.1626e-04,\n","            9.9541e-09, 3.0098e-08, 7.4509e-09, 2.4011e-07, 4.1844e-04, 6.4575e-05,\n","            4.2362e-05, 7.4279e-07, 5.0680e-08, 3.5657e-10, 2.6097e-05, 6.5143e-06,\n","            8.6970e-05, 5.3923e-05, 5.2308e-06, 3.9385e-04, 7.8569e-04, 5.0006e-06,\n","            1.7194e-08, 5.8501e-04, 1.2231e-03, 1.1158e-04],\n","           [6.8365e-03, 1.0006e-05, 5.9620e-06, 2.8011e-10, 1.2106e-05, 8.0499e-05,\n","            6.6918e-06, 9.2113e-03, 6.1173e-05, 9.6112e-04, 3.1149e-03, 1.0563e-09,\n","            1.0038e-06, 3.3868e-07, 2.4700e-05, 4.7983e-07, 4.0735e-09, 4.0436e-09,\n","            4.5279e-14, 3.9166e-04, 1.0059e-04, 8.4602e-06, 8.7617e-04, 7.0433e-03,\n","            9.5739e-05, 1.7575e-06, 2.9979e-06, 4.3458e-05, 3.7536e-07, 5.1371e-04,\n","            1.9910e-07, 2.1460e-10, 1.7592e-04, 3.6368e-05, 6.0347e-07, 2.9588e-03,\n","            8.5333e-04, 1.4968e-06, 5.2371e-06, 1.0188e-08, 1.6931e-02, 4.6713e-04,\n","            1.1991e-05, 2.2286e-10, 3.0865e-08, 6.1177e-08, 5.0353e-06, 1.3004e-05,\n","            1.2105e-03, 3.2190e-06, 5.4871e-11, 6.7748e-12, 2.0190e-04, 1.9602e-04,\n","            2.0639e-03, 5.7634e-07, 7.8389e-06, 2.1620e-03, 7.1821e-06, 2.2378e-07,\n","            4.5457e-10, 2.4386e-06, 3.1564e-04, 7.1040e-06]], device='cuda:0')},\n","  7: {'step': tensor(4690.),\n","   'exp_avg': tensor([ 8.4582e-03, -6.7572e-05,  4.2825e-03, -4.6682e-03,  3.4197e-03,\n","            6.8243e-04, -1.0722e-02,  3.1026e-04, -5.9613e-04, -1.0991e-03],\n","          device='cuda:0'),\n","   'exp_avg_sq': tensor([4.8464e-04, 6.0112e-05, 5.6405e-04, 3.2783e-04, 6.3757e-04, 1.7120e-04,\n","           8.4464e-04, 2.3957e-04, 8.9078e-05, 1.6291e-04], device='cuda:0')}},\n"," 'param_groups': [{'lr': 0.003,\n","   'betas': (0.9, 0.999),\n","   'eps': 1e-08,\n","   'weight_decay': 0,\n","   'amsgrad': False,\n","   'maximize': False,\n","   'foreach': None,\n","   'capturable': False,\n","   'differentiable': False,\n","   'fused': None,\n","   'params': [0, 1, 2, 3, 4, 5, 6, 7]}]}"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["* 위 state dictionary를 `torch.save`를 사용하여 저장하면 됩니다\n","* 예를 들어서 이름을 `checkpoint.pth`로 저장하도록 해보죠\n"],"metadata":{"id":"6Tgf8oiPG_C9"}},{"cell_type":"code","source":["torch.save(model.state_dict(), 'model_statedict.pth')"],"metadata":{"trusted":true,"id":"BO3mVQPyG_C-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 위 저장된 state dict를 다시  `torch.load`를 통해서 불러올 수 있습니다"],"metadata":{"id":"_wqrhrPOG_C-"}},{"cell_type":"code","source":["state_dict = torch.load('model_statedict.pth')\n","print(state_dict.keys())"],"metadata":{"trusted":true,"id":"Wt6g_tZzG_C-","executionInfo":{"status":"ok","timestamp":1686577652874,"user_tz":-540,"elapsed":49,"user":{"displayName":"전찬수","userId":"10602042438598641223"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a1136809-aec0-437e-b0de-e3dd32a81057"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["odict_keys(['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias'])\n"]}]},{"cell_type":"markdown","source":["* 저장된 state dict를 모델이 적용하기 위해서는 다음과 같은 명령어를 사용합니다\"\n","  * `model.load_state_dict(state_dict)`."],"metadata":{"id":"FRH1RKZoG_C-"}},{"cell_type":"code","source":["model.load_state_dict(state_dict) #받을 모델 생성"],"metadata":{"trusted":true,"id":"uRP2rel_G_C_","executionInfo":{"status":"ok","timestamp":1686577652874,"user_tz":-540,"elapsed":36,"user":{"displayName":"전찬수","userId":"10602042438598641223"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3ab9a342-c292-4f56-9b8d-256a2d682504"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["torch.save(optimizer.state_dict(), 'opt_statedict.pth')"],"metadata":{"trusted":true,"id":"mDd0RAy8G_C_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["opt_state_dict = torch.load('opt_statedict.pth')"],"metadata":{"trusted":true,"id":"9oqgit5DG_C_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer.load_state_dict(opt_state_dict)"],"metadata":{"trusted":true,"id":"z1f51R0IG_C_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer.state_dict()"],"metadata":{"id":"DCmSPZX_hAI0","executionInfo":{"status":"ok","timestamp":1686577652876,"user_tz":-540,"elapsed":35,"user":{"displayName":"전찬수","userId":"10602042438598641223"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"45c7955e-1607-4781-ffc5-f43ce0a66c8e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'state': {0: {'step': tensor(4690.),\n","   'exp_avg': tensor([[-4.5946e-04, -4.5939e-04, -4.5972e-04,  ..., -4.9390e-04,\n","            -4.6272e-04, -4.5935e-04],\n","           [-4.1300e-04, -4.1286e-04, -4.1318e-04,  ..., -4.1659e-04,\n","            -4.1487e-04, -4.1310e-04],\n","           [ 4.2755e-05,  4.2748e-05,  4.2748e-05,  ...,  4.6717e-05,\n","             4.2581e-05,  4.2781e-05],\n","           ...,\n","           [ 2.3426e-05,  2.3426e-05,  2.3426e-05,  ...,  2.3282e-05,\n","             2.3444e-05,  2.3431e-05],\n","           [ 9.8046e-05,  9.8046e-05,  9.8047e-05,  ...,  9.7638e-05,\n","             9.7794e-05,  9.8022e-05],\n","           [ 1.5705e-04,  1.5705e-04,  1.5724e-04,  ...,  1.5411e-04,\n","             1.5727e-04,  1.5717e-04]], device='cuda:0'),\n","   'exp_avg_sq': tensor([[5.9977e-06, 5.9926e-06, 5.9849e-06,  ..., 5.7150e-06, 5.8768e-06,\n","            5.9882e-06],\n","           [1.9716e-06, 1.9713e-06, 1.9692e-06,  ..., 1.9019e-06, 1.9571e-06,\n","            1.9696e-06],\n","           [1.4095e-06, 1.4088e-06, 1.4085e-06,  ..., 1.3727e-06, 1.3625e-06,\n","            1.4088e-06],\n","           ...,\n","           [5.4106e-07, 5.4096e-07, 5.4085e-07,  ..., 5.2647e-07, 5.3783e-07,\n","            5.4048e-07],\n","           [2.0120e-06, 2.0108e-06, 2.0022e-06,  ..., 1.9941e-06, 2.0061e-06,\n","            2.0111e-06],\n","           [2.9965e-06, 2.9961e-06, 2.9954e-06,  ..., 2.9434e-06, 2.9792e-06,\n","            2.9952e-06]], device='cuda:0')},\n","  1: {'step': tensor(4690.),\n","   'exp_avg': tensor([ 4.5946e-04,  4.1300e-04, -4.2755e-05, -1.8020e-04,  1.3787e-04,\n","            3.0067e-08,  5.6052e-45,  5.6052e-45,  2.3840e-17,  5.6052e-45,\n","            9.7061e-39, -5.2156e-04,  5.6052e-45,  9.2946e-06, -2.2226e-05,\n","            2.5629e-06, -2.4590e-04, -7.2376e-05,  2.3918e-28,  5.8579e-08,\n","           -9.8192e-05,  5.6052e-45, -3.2662e-04, -7.2910e-07,  5.6052e-45,\n","            1.5166e-04,  3.2409e-06,  2.0277e-04,  5.6052e-45,  1.5610e-07,\n","           -5.1407e-08,  4.2464e-04, -4.9995e-06,  5.6052e-45, -3.2812e-08,\n","            5.6052e-45,  2.9284e-04,  5.9670e-05, -6.4807e-05, -1.0477e-05,\n","            2.6184e-21,  6.9607e-08,  5.6052e-45, -2.3049e-08, -2.9643e-08,\n","           -5.5067e-04,  5.6052e-45,  1.3313e-09,  2.0727e-04, -5.2343e-09,\n","           -1.1179e-07,  1.4634e-05, -6.1297e-07,  9.1182e-09,  7.8884e-06,\n","           -1.0720e-03,  3.9612e-06,  2.1236e-05,  3.5712e-04,  1.4369e-05,\n","           -5.7887e-06, -4.0053e-06, -3.0477e-08,  1.1874e-06,  2.2712e-04,\n","           -1.6978e-06, -1.9460e-04,  5.6052e-45,  5.6052e-45, -6.6247e-22,\n","            1.0251e-06,  5.6052e-45, -1.3117e-06,  8.1163e-07,  6.4296e-07,\n","            8.4996e-07,  5.6052e-45,  9.7991e-39,  1.3358e-04, -4.9249e-11,\n","           -1.9730e-05,  5.6052e-45,  8.8942e-07,  5.6052e-45, -3.8372e-04,\n","            1.3668e-03,  6.9872e-13, -1.4110e-05, -2.5916e-11,  3.5461e-04,\n","           -1.7955e-07, -7.8231e-12,  6.0577e-16, -4.4143e-06, -6.2048e-04,\n","           -2.2286e-06, -3.5980e-11,  1.1168e-04,  5.6052e-45,  1.0006e-38,\n","            1.0829e-11,  8.3338e-12,  1.8637e-03,  5.6593e-09,  5.6052e-45,\n","           -2.6841e-28, -3.3729e-07,  5.6052e-45,  2.1005e-04,  1.0825e-08,\n","           -2.2971e-04, -3.4418e-04, -3.4545e-14, -5.1289e-14,  5.6052e-45,\n","            5.6052e-45, -7.2490e-16,  4.4896e-05, -5.3030e-06, -1.0358e-06,\n","            2.0804e-06,  5.6052e-45, -5.5908e-07, -2.4852e-06, -4.8135e-08,\n","            1.7271e-08, -4.2598e-11,  1.5739e-08, -1.3128e-28,  1.3603e-07,\n","            1.7330e-05,  3.6367e-06, -1.2397e-30, -6.1689e-05, -3.5313e-43,\n","           -5.3526e-07, -1.0641e-05, -1.3670e-04,  8.5983e-08,  5.6052e-45,\n","            9.8935e-06,  3.7967e-05, -2.9379e-20, -1.7377e-04, -4.5567e-04,\n","            3.0603e-04, -6.9145e-05, -1.7001e-04,  1.1996e-04, -3.6219e-08,\n","            7.8707e-04,  3.7496e-04,  2.7094e-27, -4.9229e-05,  5.6052e-45,\n","            5.6052e-45, -1.5690e-04, -5.2274e-05, -6.0345e-05, -3.4040e-04,\n","            2.9685e-28,  2.2638e-04,  5.6052e-45, -9.5349e-06,  4.3162e-28,\n","           -1.6960e-05, -3.3147e-11,  5.9562e-08, -3.8079e-04,  2.0515e-05,\n","            3.4078e-07,  1.2115e-26, -4.4027e-07, -1.7225e-40, -1.3289e-07,\n","           -3.8556e-19,  5.6052e-45,  1.1682e-03, -6.8049e-04, -1.8384e-09,\n","            4.3408e-06,  2.3562e-05, -1.6793e-04,  2.2818e-04,  5.6052e-45,\n","            5.6052e-45,  8.1046e-27,  1.8588e-05, -4.5111e-10,  1.3820e-23,\n","           -2.9579e-05, -3.1495e-04,  1.6535e-43,  9.9649e-07,  3.7641e-04,\n","            5.6052e-45, -2.7055e-06,  5.4170e-29, -6.6449e-07, -2.4204e-14,\n","            6.3645e-04, -1.4987e-04, -2.7365e-14,  4.0729e-13, -4.3092e-28,\n","           -2.7535e-28,  1.2714e-03, -4.5653e-04,  5.6052e-45,  1.5644e-04,\n","           -2.0511e-06,  2.2277e-04, -3.4615e-04,  1.0774e-08,  5.6052e-45,\n","           -5.8267e-04,  2.7475e-04,  5.6052e-45,  5.6052e-45, -1.7517e-04,\n","           -1.2924e-10,  1.1193e-04,  1.9421e-06, -1.7950e-06,  5.6052e-45,\n","            2.3895e-13,  5.7391e-16, -1.9209e-07,  5.3134e-05,  1.9603e-13,\n","            6.4180e-04,  1.7795e-06, -3.0114e-29,  5.6052e-45, -2.7311e-04,\n","            5.6052e-45,  5.6052e-45,  7.2132e-09,  5.6052e-45, -1.0150e-04,\n","           -5.6052e-45, -7.3782e-09,  3.4911e-04, -5.0050e-06,  3.6581e-05,\n","            3.3954e-05,  2.4065e-04,  2.5451e-05,  5.6052e-45, -3.1891e-15,\n","            5.6052e-45,  2.1791e-04,  1.7966e-29, -2.3426e-05, -9.8046e-05,\n","           -1.5705e-04], device='cuda:0'),\n","   'exp_avg_sq': tensor([5.9979e-06, 1.9716e-06, 1.4095e-06, 1.6062e-06, 4.4225e-06, 2.8363e-11,\n","           1.1885e-12, 3.3328e-12, 4.6509e-11, 2.1715e-11, 3.7965e-11, 2.8915e-06,\n","           3.5038e-11, 4.8262e-07, 2.7734e-06, 3.5130e-07, 3.8207e-07, 1.5280e-06,\n","           1.9797e-08, 3.7838e-08, 1.3664e-06, 1.9884e-11, 3.3262e-06, 2.5984e-08,\n","           4.8906e-10, 2.5114e-06, 8.2075e-08, 1.1904e-06, 6.1923e-11, 3.5234e-08,\n","           2.5317e-09, 1.7406e-06, 3.9014e-08, 2.5286e-11, 9.8833e-09, 4.2169e-13,\n","           8.4355e-07, 9.1406e-07, 3.5142e-07, 3.8388e-07, 4.1368e-09, 6.1700e-09,\n","           6.3032e-12, 6.2030e-08, 5.1194e-08, 1.2479e-05, 1.7003e-11, 4.6309e-07,\n","           2.3710e-06, 1.6964e-09, 5.6783e-08, 1.0656e-07, 4.1311e-08, 5.5045e-10,\n","           3.6636e-07, 1.1096e-05, 1.2780e-07, 2.4238e-08, 3.0177e-06, 6.7326e-07,\n","           5.3117e-07, 5.1410e-08, 6.2873e-10, 2.2439e-09, 8.4912e-08, 5.9769e-08,\n","           2.0649e-06, 2.1772e-13, 3.5427e-14, 1.0860e-08, 3.6946e-08, 2.3114e-12,\n","           1.0473e-06, 2.4926e-08, 6.1079e-09, 2.1095e-08, 5.2533e-11, 1.0547e-08,\n","           2.1630e-06, 1.4304e-08, 5.3126e-06, 4.2780e-11, 2.4778e-08, 3.7953e-13,\n","           1.5551e-06, 3.3906e-06, 6.1072e-09, 4.4319e-07, 5.0145e-08, 2.2986e-06,\n","           5.2576e-08, 1.8424e-08, 1.6101e-09, 1.2629e-07, 5.2044e-06, 2.2913e-08,\n","           2.0853e-08, 4.0933e-07, 2.5470e-11, 3.8680e-11, 3.1281e-09, 1.0455e-08,\n","           8.2668e-06, 2.5629e-09, 4.7273e-10, 5.6066e-10, 7.6719e-08, 8.1350e-13,\n","           2.1062e-06, 7.5435e-09, 9.7473e-07, 2.0808e-06, 9.0168e-11, 1.1519e-08,\n","           4.2357e-11, 1.0510e-11, 1.0322e-09, 8.6518e-08, 1.8065e-08, 1.3114e-07,\n","           7.6357e-08, 3.4043e-11, 3.0813e-09, 1.5008e-08, 3.5399e-08, 1.4236e-07,\n","           6.0138e-09, 8.4850e-09, 3.4629e-09, 5.1187e-09, 4.6881e-07, 1.3365e-07,\n","           4.2145e-11, 9.3748e-07, 7.9447e-09, 1.2857e-08, 4.0272e-08, 4.9836e-07,\n","           5.3346e-08, 6.2766e-13, 2.3488e-08, 1.6700e-06, 7.1438e-10, 1.0802e-06,\n","           1.4040e-06, 7.5716e-06, 2.9187e-07, 4.3667e-06, 1.8996e-06, 4.2346e-08,\n","           1.4855e-07, 2.0133e-07, 3.3893e-09, 1.0789e-06, 7.0405e-10, 3.6177e-11,\n","           1.7849e-06, 4.4609e-06, 6.0214e-07, 1.9304e-06, 2.8549e-10, 1.5679e-06,\n","           3.2577e-14, 8.9137e-07, 7.4650e-10, 1.1732e-06, 6.1615e-09, 4.9579e-09,\n","           4.5189e-07, 1.3996e-06, 2.2026e-08, 8.1027e-10, 4.2986e-11, 5.0703e-10,\n","           1.6475e-08, 3.0490e-10, 1.2699e-11, 5.0003e-06, 5.2307e-06, 9.6309e-09,\n","           3.3023e-09, 4.0466e-06, 9.2468e-07, 1.6747e-06, 2.0679e-12, 1.0008e-11,\n","           2.6291e-10, 7.4124e-08, 7.4779e-09, 4.7868e-12, 9.3111e-08, 2.2548e-06,\n","           8.1277e-10, 1.8664e-06, 1.0944e-06, 1.0708e-11, 3.0014e-07, 3.0938e-11,\n","           7.4677e-07, 2.0814e-09, 2.6516e-06, 1.0159e-05, 6.2450e-10, 1.0948e-09,\n","           9.5578e-11, 2.5920e-10, 3.6298e-06, 6.4569e-07, 1.2838e-11, 7.2255e-07,\n","           1.4198e-07, 6.6886e-07, 4.7728e-06, 4.9896e-09, 1.5314e-10, 5.2881e-06,\n","           7.2202e-06, 3.8670e-12, 6.5023e-11, 1.5372e-06, 4.2094e-09, 9.3847e-07,\n","           3.5431e-06, 4.5185e-08, 5.8793e-11, 1.0604e-08, 1.1150e-09, 1.4101e-08,\n","           3.9943e-06, 8.5640e-09, 7.6123e-06, 1.0558e-08, 1.8445e-09, 5.5955e-13,\n","           3.0646e-06, 2.9695e-10, 1.8575e-10, 5.1062e-08, 4.0664e-11, 3.8053e-06,\n","           9.6313e-11, 2.4239e-08, 5.3985e-06, 3.3781e-07, 3.5341e-07, 3.4721e-07,\n","           5.4328e-07, 7.4462e-07, 4.4024e-10, 4.5821e-09, 1.4143e-11, 6.6578e-07,\n","           3.4533e-09, 5.4106e-07, 2.0120e-06, 2.9965e-06], device='cuda:0')},\n","  2: {'step': tensor(4690.),\n","   'exp_avg': tensor([[-2.3959e-04,  6.5844e-05, -3.5661e-04,  ..., -3.6959e-38,\n","             1.1167e-04, -7.5967e-04],\n","           [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n","             5.6052e-45,  5.6052e-45],\n","           [ 1.4218e-08,  3.5484e-11, -2.8503e-06,  ...,  4.6717e-37,\n","             3.2243e-09, -9.5032e-09],\n","           ...,\n","           [ 3.0448e-03, -3.0965e-04, -4.7556e-04,  ...,  3.5119e-07,\n","             1.5947e-04,  2.7238e-04],\n","           [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n","             5.6052e-45,  5.6052e-45],\n","           [-3.4287e-06,  1.7940e-05, -1.2805e-07,  ...,  5.1819e-18,\n","             2.3303e-05,  2.6654e-05]], device='cuda:0'),\n","   'exp_avg_sq': tensor([[8.9784e-06, 1.2934e-06, 1.4419e-05,  ..., 5.0079e-06, 9.1441e-06,\n","            1.5979e-05],\n","           [7.8079e-15, 3.3083e-12, 2.7521e-12,  ..., 5.2686e-13, 3.1560e-13,\n","            2.1201e-14],\n","           [2.1073e-06, 4.6061e-08, 7.9008e-07,  ..., 1.0688e-07, 2.3382e-07,\n","            2.1890e-07],\n","           ...,\n","           [2.6385e-05, 1.3252e-05, 4.8699e-05,  ..., 2.7264e-05, 3.1219e-05,\n","            1.6538e-04],\n","           [9.6676e-09, 6.8800e-12, 1.1105e-09,  ..., 3.5848e-12, 1.1533e-09,\n","            6.9232e-11],\n","           [3.6245e-06, 6.3495e-08, 2.0212e-08,  ..., 8.4875e-08, 2.6652e-06,\n","            4.0772e-06]], device='cuda:0')},\n","  3: {'step': tensor(4690.),\n","   'exp_avg': tensor([-9.9349e-05,  5.6052e-45, -8.0048e-07, -6.9435e-05, -5.3513e-05,\n","           -8.7977e-05,  5.9942e-05,  7.6001e-07, -8.7329e-05, -2.3587e-06,\n","            2.7615e-04, -3.1613e-05, -9.3331e-05,  1.8925e-04, -2.9430e-06,\n","            9.8249e-17,  5.2961e-24, -1.8136e-04, -1.0663e-04,  1.9155e-04,\n","            5.6052e-45,  8.6997e-06,  3.9864e-04, -1.8177e-08, -4.7670e-05,\n","           -4.8539e-05,  2.8027e-10,  3.0812e-04,  2.5788e-04,  8.7827e-04,\n","            6.2599e-05, -2.7166e-06,  3.8587e-04, -1.3583e-05,  2.0144e-07,\n","           -1.6358e-04, -2.3043e-28, -3.4958e-05,  1.0069e-24,  2.6828e-04,\n","           -1.4995e-04, -4.7941e-05,  5.6052e-45,  5.7490e-05,  1.0035e-05,\n","           -2.6827e-04, -6.0914e-09,  1.7151e-18,  1.9231e-05,  5.6052e-45,\n","            2.7303e-04,  5.9555e-05, -3.3957e-04, -6.6853e-06, -1.9489e-09,\n","           -1.7159e-04, -1.9838e-05,  1.0074e-04,  5.6052e-45, -2.7488e-05,\n","            5.2263e-05, -2.2790e-04, -1.3305e-04, -1.8988e-05,  1.5218e-04,\n","            1.0854e-05,  1.4571e-04, -1.2566e-05, -5.9952e-05, -6.1287e-05,\n","            7.8955e-04,  2.6709e-04, -2.7998e-05,  1.5750e-07, -4.6182e-05,\n","           -6.4478e-04, -1.2933e-04, -2.2900e-05, -1.2666e-04,  1.2820e-04,\n","           -1.3630e-04,  9.6959e-30,  5.1673e-04,  3.1060e-04, -9.4018e-05,\n","           -4.1564e-05,  2.4904e-05, -2.1773e-04, -2.6282e-04,  4.1293e-05,\n","            1.6121e-04,  3.5327e-04, -4.4088e-05, -8.7888e-13, -1.9261e-05,\n","            8.8270e-05, -2.9150e-04,  1.8721e-05,  5.3528e-05, -1.3249e-04,\n","           -9.0904e-05,  9.2342e-05, -1.2871e-04, -1.7451e-04, -2.2203e-04,\n","           -6.0738e-09, -9.9825e-06,  2.9990e-04,  5.3288e-04, -3.1040e-05,\n","           -9.9140e-05,  2.1448e-04, -2.0029e-12, -5.4768e-15,  2.3646e-05,\n","            9.0499e-17,  3.0655e-04, -2.8350e-04, -4.6180e-06,  1.1384e-04,\n","           -4.1391e-05,  1.1972e-03,  3.5750e-04, -4.7551e-04, -3.7133e-05,\n","           -5.9657e-05,  5.6052e-45,  2.2673e-05], device='cuda:0'),\n","   'exp_avg_sq': tensor([1.1435e-06, 1.8777e-12, 4.1188e-08, 1.6581e-06, 2.2338e-07, 1.4222e-06,\n","           1.4849e-07, 1.2747e-07, 6.8046e-07, 8.4222e-08, 1.6201e-06, 2.2313e-06,\n","           3.9641e-06, 3.9285e-07, 6.0677e-07, 5.1292e-11, 1.9055e-11, 1.1594e-06,\n","           3.5017e-06, 2.3979e-07, 1.6017e-11, 8.4641e-07, 2.8460e-06, 1.4263e-08,\n","           1.6105e-07, 1.0877e-06, 7.6022e-08, 1.5532e-06, 4.2128e-07, 4.2131e-06,\n","           5.0412e-06, 1.0640e-07, 1.3513e-06, 5.1569e-07, 3.4411e-09, 2.7367e-06,\n","           2.7987e-10, 4.5455e-06, 2.4706e-10, 2.2943e-06, 6.8045e-07, 1.2707e-06,\n","           1.0061e-09, 3.1510e-06, 6.5532e-07, 7.0393e-07, 3.6915e-09, 3.3684e-09,\n","           7.3603e-07, 1.0490e-10, 2.0334e-06, 6.7373e-07, 6.6637e-07, 4.1378e-08,\n","           1.4418e-08, 6.1133e-07, 2.6124e-06, 3.8855e-07, 7.9031e-10, 1.0679e-06,\n","           2.3425e-07, 8.5835e-07, 3.2316e-07, 1.4693e-06, 2.1457e-06, 1.6610e-06,\n","           1.6973e-06, 5.7284e-08, 2.2446e-06, 1.4478e-08, 4.2896e-06, 1.6048e-06,\n","           2.6088e-07, 5.0963e-08, 1.1544e-06, 2.0384e-06, 8.6956e-07, 4.8424e-09,\n","           5.0379e-07, 4.6088e-07, 7.4688e-07, 1.2199e-08, 1.0586e-06, 3.6993e-06,\n","           9.8181e-08, 1.2869e-06, 1.9022e-06, 2.0499e-06, 1.9949e-06, 1.2515e-07,\n","           3.5181e-07, 3.4762e-06, 1.5197e-07, 1.4281e-10, 1.3588e-07, 3.2527e-06,\n","           1.4581e-06, 4.5083e-07, 2.2989e-07, 6.9945e-07, 1.2412e-06, 1.7410e-06,\n","           7.5556e-07, 2.8460e-07, 2.0172e-06, 2.7342e-08, 2.9501e-07, 2.0697e-06,\n","           4.6623e-06, 1.0311e-08, 3.9059e-07, 9.7606e-07, 4.3072e-09, 7.4917e-11,\n","           5.5400e-07, 7.2892e-09, 1.6296e-06, 2.1966e-06, 7.4672e-08, 1.7826e-07,\n","           5.9053e-07, 1.5526e-06, 1.2427e-06, 2.8430e-06, 3.4302e-07, 3.2940e-06,\n","           3.1996e-10, 1.5462e-07], device='cuda:0')},\n","  4: {'step': tensor(4690.),\n","   'exp_avg': tensor([[ 4.5820e-04, -5.6052e-45, -1.7669e-16,  ...,  1.1027e-03,\n","            -5.6052e-45, -1.8877e-07],\n","           [ 9.5107e-05, -5.6052e-45, -1.3860e-15,  ...,  2.8767e-03,\n","             5.6052e-45,  7.7276e-06],\n","           [ 9.2302e-37,  5.6052e-45, -5.6052e-45,  ...,  2.0621e-14,\n","            -5.6052e-45,  5.6052e-45],\n","           ...,\n","           [ 3.2182e-06, -5.6052e-45, -2.1431e-10,  ..., -1.1384e-03,\n","             5.6052e-45, -9.0094e-06],\n","           [-6.8693e-04,  0.0000e+00,  7.9415e-08,  ..., -7.3693e-04,\n","             5.6052e-45, -6.2375e-06],\n","           [-9.3346e-04, -5.6052e-45, -4.4654e-08,  ...,  1.2986e-03,\n","            -5.6052e-45, -6.6115e-06]], device='cuda:0'),\n","   'exp_avg_sq': tensor([[2.2688e-05, 9.8083e-15, 6.3078e-07,  ..., 8.1467e-05, 1.6711e-12,\n","            1.8771e-06],\n","           [1.7142e-05, 9.5574e-15, 1.2049e-06,  ..., 2.6675e-04, 3.8352e-13,\n","            2.1335e-06],\n","           [1.6316e-07, 5.0169e-15, 8.5211e-09,  ..., 4.7162e-07, 3.2712e-14,\n","            6.4999e-15],\n","           ...,\n","           [1.1958e-05, 4.2169e-13, 1.5189e-06,  ..., 1.1001e-04, 6.0155e-11,\n","            1.9127e-06],\n","           [3.3552e-05, 0.0000e+00, 1.5157e-06,  ..., 2.9451e-05, 2.8377e-11,\n","            8.6107e-07],\n","           [3.1753e-05, 1.2907e-13, 1.3591e-06,  ..., 3.2900e-05, 2.4783e-11,\n","            1.9176e-06]], device='cuda:0')},\n","  5: {'step': tensor(4690.),\n","   'exp_avg': tensor([ 2.6211e-04,  3.2109e-04,  2.7427e-15,  2.4533e-17,  4.5221e-05,\n","           -3.6549e-04,  5.1469e-04,  5.0664e-05,  5.8585e-04, -4.9767e-05,\n","            9.6778e-05,  5.6052e-45,  1.0247e-04, -2.7584e-05, -4.6167e-04,\n","           -4.5142e-06,  9.5003e-09, -2.2138e-04,  2.2999e-10, -2.8600e-04,\n","            1.1028e-06, -1.8818e-05,  4.8081e-05,  3.0891e-04,  5.9343e-05,\n","            9.8218e-08,  7.3712e-04,  4.1985e-04,  2.0796e-05, -1.6451e-04,\n","            2.3578e-11,  5.6052e-45, -4.4680e-04,  4.1372e-04, -4.1788e-06,\n","            5.7876e-04,  2.0651e-04,  1.1872e-03, -1.5488e-04,  1.2292e-04,\n","            2.2611e-04,  1.3270e-04,  9.5955e-06,  3.5434e-31,  5.6052e-45,\n","           -1.2963e-11, -8.3034e-04,  8.7519e-05, -3.8436e-05,  3.9302e-10,\n","            8.1079e-06,  5.6052e-45, -7.7853e-05,  5.5264e-05, -1.3796e-04,\n","            9.8374e-05,  1.8783e-07,  1.5421e-04,  1.0654e-04, -7.2487e-06,\n","            3.2639e-13,  1.0778e-04, -2.1045e-04,  1.4805e-03], device='cuda:0'),\n","   'exp_avg_sq': tensor([2.1695e-06, 1.6486e-05, 5.8983e-08, 7.0379e-10, 1.1274e-05, 8.1369e-06,\n","           9.8816e-06, 5.7023e-06, 1.5125e-05, 9.0423e-07, 1.4194e-06, 7.3973e-10,\n","           1.0480e-05, 8.4469e-08, 1.7822e-05, 1.9986e-07, 1.2637e-08, 1.3594e-06,\n","           1.2966e-09, 3.5300e-06, 1.3319e-07, 3.3094e-07, 2.8921e-05, 3.0094e-06,\n","           1.0090e-06, 7.8862e-08, 4.7327e-06, 1.8928e-06, 4.2056e-06, 2.4459e-06,\n","           5.8728e-08, 1.6404e-09, 6.9372e-06, 5.8374e-06, 2.6454e-07, 4.4650e-06,\n","           1.7294e-06, 6.2599e-06, 1.9858e-07, 1.9738e-06, 3.8973e-06, 2.9743e-06,\n","           3.2354e-08, 5.1075e-08, 3.9057e-09, 2.3671e-08, 9.1029e-06, 9.9189e-06,\n","           2.3602e-06, 2.8931e-08, 1.4832e-08, 8.2012e-10, 4.1001e-06, 1.8842e-07,\n","           1.7611e-06, 7.5745e-07, 9.9019e-08, 8.3656e-06, 5.3615e-06, 8.4199e-07,\n","           9.3114e-09, 1.6534e-05, 2.6345e-06, 1.1071e-05], device='cuda:0')},\n","  6: {'step': tensor(4690.),\n","   'exp_avg': tensor([[ 1.7457e-05,  2.9452e-03,  3.7070e-18,  7.8149e-20,  3.7393e-03,\n","             1.0379e-03,  6.2955e-03, -1.0516e-05,  2.0469e-03,  7.2177e-05,\n","            -1.4477e-05, -5.6052e-45,  3.7872e-02,  1.7597e-05,  5.6665e-03,\n","             6.6083e-05,  4.0648e-13,  5.1636e-04,  9.7895e-12, -2.7191e-03,\n","             3.7980e-05,  1.2935e-03,  7.7500e-02,  1.0796e-03,  1.5746e-04,\n","             2.8200e-07,  1.3297e-02,  8.4360e-04,  3.0652e-03,  1.3447e-03,\n","            -1.1702e-09,  5.6052e-45, -1.2902e-03,  1.5897e-03,  6.0685e-05,\n","             1.0734e-02,  8.8031e-06,  3.8740e-02,  5.2388e-03,  1.8206e-04,\n","             3.9944e-05,  7.9256e-04,  1.3033e-06,  2.0168e-30,  5.6052e-45,\n","             2.4189e-10,  1.6035e-03,  2.5734e-03, -7.1732e-04,  1.1430e-09,\n","             4.8478e-06,  5.6052e-45,  4.8083e-03,  6.9614e-05,  7.7818e-04,\n","             2.8136e-05,  8.7755e-10,  3.3113e-04,  2.5280e-02,  1.8942e-05,\n","            -2.3345e-11,  3.0813e-02,  3.8718e-04,  2.0292e-02],\n","           [ 3.7329e-06,  5.2124e-03,  2.6163e-19,  6.4754e-22,  1.8439e-03,\n","             4.3251e-05, -4.6973e-03, -1.6187e-03,  5.2277e-04,  4.3473e-06,\n","             1.0299e-04,  5.6052e-45, -7.2873e-03, -2.5806e-04, -1.1838e-02,\n","            -5.9541e-05,  5.3916e-16,  1.3666e-05,  2.2417e-12,  1.1488e-04,\n","             5.1184e-08,  1.3418e-07, -1.2070e-04, -2.5460e-03,  2.2380e-06,\n","             1.1709e-09, -1.1270e-03,  9.1363e-05,  6.5829e-04, -4.9257e-06,\n","             1.0449e-10,  5.6052e-45,  8.5730e-04,  1.1016e-03,  3.7375e-07,\n","             5.4223e-05,  1.7119e-06,  9.1638e-04,  1.0251e-05,  4.0827e-05,\n","             9.4108e-06,  2.2004e-04,  8.9596e-06,  1.8034e-32,  5.6052e-45,\n","            -9.2597e-10,  1.7587e-04,  5.4038e-04, -2.6209e-03, -1.9251e-09,\n","             2.8499e-08,  5.6052e-45, -4.5967e-04,  3.9886e-09,  1.9656e-05,\n","             1.4963e-03,  1.5409e-10, -2.9829e-03,  8.3408e-04,  2.8911e-05,\n","             3.7323e-16,  1.3179e-03,  2.0778e-06, -3.3404e-03],\n","           [ 6.4683e-06,  1.2170e-02,  5.7392e-19,  8.2224e-21, -3.5485e-03,\n","             8.5907e-03,  4.7106e-02,  4.0125e-05,  4.9512e-02,  9.2755e-06,\n","             1.2741e-05,  5.6052e-45, -8.1632e-03,  2.6065e-05,  2.8297e-03,\n","             2.2151e-05, -6.5880e-09,  1.5763e-03,  5.0362e-11, -1.2705e-03,\n","             1.3322e-06,  3.4158e-06, -2.3040e-02,  1.8214e-02, -1.3272e-04,\n","             9.0525e-08, -5.2559e-03,  2.2757e-04,  2.3925e-02, -2.0006e-04,\n","             7.7080e-11,  5.6052e-45, -1.5927e-04,  3.4435e-04,  1.3382e-06,\n","            -3.2548e-03,  2.4182e-06, -3.5081e-03,  1.4220e-04,  2.3176e-03,\n","             5.4362e-06,  5.1725e-04,  5.2802e-07, -6.1530e-31,  5.6052e-45,\n","             1.2258e-10, -6.3889e-04, -1.9094e-03,  8.3860e-05,  3.9334e-10,\n","             1.0169e-05,  5.6052e-45, -8.1832e-04, -1.4234e-06,  5.9417e-05,\n","             3.8964e-04,  2.3497e-10, -6.5887e-06, -1.1551e-02,  3.8468e-03,\n","             7.5350e-12,  4.0118e-03,  4.4642e-05,  2.6083e-02],\n","           [ 5.7026e-06, -1.8305e-02,  2.5361e-18,  4.7233e-21, -8.8873e-03,\n","             9.7464e-04,  4.7227e-03,  1.9473e-03,  6.5242e-04,  5.5438e-06,\n","             6.1297e-05,  5.6052e-45, -2.7675e-02,  2.8245e-04, -1.3719e-02,\n","             2.7250e-04,  2.8754e-16,  2.6520e-04,  9.5757e-12, -2.7412e-03,\n","             2.0737e-08,  7.5888e-06, -2.8130e-02,  2.1873e-03, -2.3129e-05,\n","             2.6286e-08, -1.1436e-02,  1.5868e-04,  4.4459e-04,  1.7115e-04,\n","             1.5154e-10,  5.6052e-45, -1.1020e-02, -5.9590e-03,  2.3767e-07,\n","             1.2534e-03,  2.4212e-06, -9.6728e-03,  4.8071e-05,  1.9216e-04,\n","             1.3019e-05, -1.1068e-03,  2.8650e-06, -1.2534e-30,  5.6052e-45,\n","             4.3004e-10,  1.7434e-03,  1.1827e-04,  4.3869e-03,  2.8668e-10,\n","             2.8427e-07,  5.6052e-45,  7.9802e-04,  5.3300e-08,  2.5790e-04,\n","            -1.5669e-03,  7.2594e-11,  3.0486e-03, -1.1627e-02,  2.0149e-05,\n","             9.3548e-13,  9.6937e-04,  9.1574e-06, -1.1925e-02],\n","           [ 6.6826e-06,  1.4636e-02,  4.0394e-18,  5.3577e-23,  1.2781e-02,\n","             1.0441e-03, -1.1912e-02,  1.8133e-05, -1.2833e-02,  2.5554e-06,\n","            -4.4799e-05,  5.6052e-45,  6.8691e-03,  8.6070e-05,  1.7092e-02,\n","             1.0381e-04,  5.7356e-11,  4.5666e-03, -1.4684e-10,  4.3340e-03,\n","             8.9651e-08,  7.2819e-06,  9.8352e-03,  3.6208e-03,  4.3002e-04,\n","             7.2895e-07,  3.6735e-03,  4.9268e-05, -8.2105e-03,  1.1738e-04,\n","             6.5832e-11,  5.6052e-45,  8.6383e-03,  5.8809e-03,  1.9136e-06,\n","             5.5588e-04,  1.6113e-06, -6.3048e-03, -1.9338e-05, -3.9028e-03,\n","             1.2546e-05, -7.1107e-05,  1.3022e-07,  4.2522e-32,  5.6052e-45,\n","             2.0220e-11,  2.4698e-02,  4.7453e-03,  6.8185e-05,  2.4798e-12,\n","             1.0594e-06,  5.6052e-45,  2.9297e-03,  7.8866e-07,  2.1100e-05,\n","            -4.3625e-04,  3.5650e-11,  1.5047e-05,  1.1502e-03, -4.2221e-03,\n","             6.3192e-13,  2.3782e-02,  2.8424e-05, -2.7747e-03],\n","           [-2.0711e-03,  7.8075e-05,  9.1136e-17, -9.9802e-17,  2.8151e-04,\n","            -1.0629e-03,  7.4099e-05,  7.9193e-03,  8.9513e-05,  5.6713e-03,\n","            -3.7979e-03,  5.6052e-45,  2.5241e-04, -2.1524e-05,  1.5711e-03,\n","             1.7523e-06,  4.9193e-17,  2.3628e-06,  2.2602e-12,  2.6568e-04,\n","             4.7585e-06,  3.7150e-06,  1.2591e-02,  9.2106e-03,  3.0806e-06,\n","             6.0409e-09,  3.3823e-05, -9.8109e-04, -4.5357e-04, -3.0295e-03,\n","             1.0060e-11,  5.6052e-45,  2.8138e-05,  1.1230e-02,  1.1222e-06,\n","             3.1638e-04, -2.6721e-03, -2.7072e-03,  1.6480e-06,  8.7438e-07,\n","            -6.9042e-03,  1.4102e-02, -4.3894e-04,  3.1896e-34,  5.6052e-45,\n","             1.4923e-14,  4.6774e-03,  1.6578e-05, -3.4787e-03,  2.3916e-15,\n","             1.3135e-09,  5.6052e-45,  5.0408e-06, -4.4512e-04, -3.6716e-04,\n","             6.9680e-07,  1.0822e-08, -3.0183e-04, -1.0849e-03,  1.0218e-08,\n","             1.0373e-16,  1.8164e-04,  1.1043e-02,  3.2901e-03],\n","           [ 2.3502e-05, -1.5679e-02,  1.4045e-17,  9.9587e-21,  1.6040e-03,\n","            -1.0764e-02, -4.1696e-02,  1.8881e-05, -3.9908e-02,  8.3656e-06,\n","             3.8158e-05,  5.6052e-45,  1.0385e-03, -1.6572e-04,  6.8178e-05,\n","            -4.2295e-04,  6.5280e-09, -6.9715e-03,  4.1655e-11,  2.2571e-03,\n","             4.1656e-06,  8.8392e-05, -3.5238e-02, -2.2681e-02, -3.4536e-04,\n","            -4.6018e-06,  1.3436e-03,  9.0790e-04, -1.9718e-02,  8.4065e-04,\n","             6.6909e-10,  5.6052e-45,  4.1566e-03, -3.5107e-03,  2.0493e-05,\n","            -4.1879e-03,  4.3867e-06, -1.9737e-02, -6.2863e-03,  1.3003e-03,\n","             4.7458e-05, -4.0602e-04,  1.3007e-07, -2.2458e-31,  5.6052e-45,\n","             1.0058e-10, -2.7721e-02, -6.3206e-03, -1.1601e-03,  5.5320e-11,\n","            -1.7150e-05, -5.6052e-45, -7.7526e-03,  6.8039e-07,  4.0401e-04,\n","             4.7251e-05,  1.9121e-10,  3.1019e-04, -9.9806e-05,  3.0332e-04,\n","             1.4227e-11, -6.0639e-02,  2.5213e-04, -2.8813e-02],\n","           [ 6.2529e-03,  1.3720e-03, -8.2138e-15,  2.0252e-17,  6.9045e-05,\n","             1.4477e-04,  1.8633e-05, -3.6590e-03,  2.2368e-05, -2.3228e-03,\n","             8.9399e-03,  5.6052e-45,  3.7249e-05,  3.3145e-07, -2.4047e-03,\n","             2.7816e-07,  1.1594e-18,  1.1833e-07,  8.1130e-13, -9.3097e-04,\n","             1.3827e-05,  7.6053e-07, -1.2149e-02, -2.8828e-03,  3.7376e-06,\n","             2.2154e-09,  4.1887e-06, -2.1856e-03,  2.2341e-06, -3.3188e-03,\n","             1.6425e-12,  5.6052e-45,  1.3107e-03, -1.1457e-02,  2.9044e-07,\n","            -9.1478e-04,  6.1360e-03,  7.2478e-06,  3.5479e-07,  4.0727e-07,\n","             1.4745e-02, -1.5382e-02,  1.0156e-05,  6.8409e-36,  5.6052e-45,\n","             9.8296e-16, -4.3679e-03,  1.4957e-06,  3.5108e-03,  1.0268e-17,\n","             3.0299e-11,  5.6052e-45,  7.9717e-06,  4.6688e-04,  1.5751e-03,\n","             1.3023e-07, -5.3845e-07,  5.9240e-03,  9.2294e-05,  6.1390e-09,\n","             2.4314e-18,  2.8186e-05, -1.2827e-02, -4.0020e-03],\n","           [ 1.1581e-04, -1.0765e-03,  1.3395e-17,  8.4381e-20, -7.9072e-03,\n","            -9.8074e-05,  7.3365e-05,  2.3854e-03, -1.1285e-04,  1.3654e-03,\n","             7.9186e-05,  5.6052e-45, -2.9805e-03,  1.1127e-05, -2.7969e-04,\n","             1.5295e-05,  2.1749e-12,  3.0552e-05,  2.8968e-11,  2.0860e-05,\n","            -4.4102e-05, -1.4053e-03, -4.4607e-04,  2.2702e-03, -9.7310e-05,\n","             3.4593e-06, -5.3776e-04,  3.7841e-04,  2.7926e-04,  2.5787e-03,\n","             8.4813e-11,  5.6052e-45, -1.2210e-03,  5.1940e-04, -8.6800e-05,\n","            -1.0496e-03,  1.7603e-04,  2.2278e-03,  8.6406e-04, -1.3235e-04,\n","             1.6147e-04,  1.8293e-04,  9.7723e-07,  1.5464e-32, -5.6052e-45,\n","             1.0653e-11, -1.9710e-04,  2.3029e-04,  5.4679e-05,  3.9554e-11,\n","             7.5989e-07,  5.6052e-45,  4.5597e-04,  4.3032e-04, -4.5106e-04,\n","             4.0933e-05,  4.1574e-07, -5.2217e-04, -3.0343e-03,  3.9596e-06,\n","             1.5962e-14, -4.9927e-04, -8.4505e-04,  8.1415e-04],\n","           [-4.3611e-03, -1.3537e-03,  8.0841e-15,  7.9363e-17,  2.4152e-05,\n","             8.9429e-05,  1.5242e-05, -7.0409e-03,  7.7209e-06, -4.8162e-03,\n","            -5.3771e-03,  5.6052e-45,  3.6833e-05,  2.1670e-05,  1.0140e-03,\n","             6.2531e-07,  1.0774e-17,  2.1739e-07,  1.1746e-12,  6.6921e-04,\n","            -1.8122e-05,  4.6510e-07, -8.0227e-04, -8.4729e-03,  1.9851e-06,\n","             5.3096e-09,  5.0460e-06,  5.0990e-04,  6.7935e-06,  1.5008e-03,\n","             5.6866e-12, -5.6052e-45, -1.3007e-03,  2.6068e-04,  3.4663e-07,\n","            -3.5063e-03, -3.6613e-03,  3.8832e-05,  2.8888e-07,  9.9648e-07,\n","            -8.1304e-03,  1.1510e-03,  4.1389e-04,  5.3782e-35,  5.6052e-45,\n","             7.6980e-15,  2.6724e-05,  4.2365e-06, -1.2725e-04,  2.8103e-16,\n","             1.2872e-10,  5.6052e-45,  2.5603e-05, -5.2179e-04, -2.2972e-03,\n","             1.1275e-07,  1.1033e-07, -5.8156e-03,  4.0708e-05,  1.4562e-08,\n","             2.2740e-17,  3.4765e-05,  1.9047e-03,  3.7539e-04]], device='cuda:0'),\n","   'exp_avg_sq': tensor([[4.1646e-06, 4.2394e-04, 6.7019e-07, 7.7390e-10, 5.3036e-04, 1.8190e-03,\n","            2.4376e-03, 5.0715e-05, 8.1697e-04, 4.9244e-06, 5.2578e-06, 6.9508e-11,\n","            3.0451e-02, 8.8139e-06, 5.9589e-03, 8.8626e-05, 1.7950e-06, 2.3118e-05,\n","            2.3357e-12, 5.9087e-04, 2.4296e-05, 1.6732e-05, 4.5811e-02, 3.0488e-05,\n","            3.5059e-05, 1.2649e-07, 6.9377e-03, 2.8511e-04, 2.4879e-04, 6.8468e-04,\n","            9.1584e-06, 8.8642e-13, 3.7921e-04, 5.3674e-04, 3.5109e-05, 8.0358e-04,\n","            5.4912e-06, 8.6094e-03, 7.9717e-05, 2.2044e-05, 9.4080e-06, 4.9689e-05,\n","            4.9975e-07, 1.1061e-05, 1.0955e-08, 4.9067e-06, 2.0844e-04, 5.3260e-03,\n","            3.1342e-04, 5.7869e-06, 5.2726e-08, 7.7234e-11, 2.2431e-03, 9.0977e-06,\n","            4.0842e-06, 3.2788e-04, 5.3629e-07, 1.0913e-04, 1.2184e-02, 2.2192e-05,\n","            4.5308e-06, 1.3188e-02, 1.9281e-04, 8.2218e-03],\n","           [5.8558e-07, 8.8883e-04, 1.8348e-05, 7.7366e-11, 1.0976e-04, 3.1255e-05,\n","            1.0515e-03, 1.3264e-04, 2.2267e-05, 1.8085e-06, 2.7338e-05, 1.2778e-12,\n","            2.4101e-03, 8.5274e-06, 5.7517e-03, 6.0747e-05, 1.2427e-07, 6.1560e-07,\n","            1.2198e-13, 8.3452e-06, 1.3938e-08, 2.3150e-06, 8.4666e-05, 8.7102e-05,\n","            9.0074e-05, 5.4968e-09, 3.1586e-04, 4.5652e-05, 4.4133e-05, 1.8726e-05,\n","            2.9745e-07, 5.1615e-13, 1.4756e-04, 1.7484e-04, 1.8370e-06, 4.3688e-05,\n","            4.2779e-06, 8.4592e-04, 8.9594e-06, 1.5249e-06, 4.0564e-07, 1.2185e-05,\n","            4.4589e-08, 5.9212e-08, 1.4942e-09, 1.0370e-05, 5.2906e-06, 1.5599e-04,\n","            1.2825e-03, 1.1253e-05, 2.5064e-10, 6.4571e-12, 4.0000e-05, 5.8595e-07,\n","            2.2104e-06, 3.2651e-04, 1.5616e-07, 4.4591e-04, 1.3610e-04, 2.4369e-05,\n","            9.6695e-09, 1.0661e-04, 1.0292e-06, 1.7621e-03],\n","           [6.4801e-07, 1.7479e-02, 6.7852e-07, 3.7535e-09, 5.9771e-03, 3.0938e-03,\n","            1.4928e-02, 1.6547e-05, 1.1895e-02, 2.7390e-06, 4.8351e-07, 2.1597e-08,\n","            1.0274e-03, 1.8721e-05, 1.9070e-03, 3.5143e-05, 2.7220e-06, 3.2250e-04,\n","            5.1781e-10, 1.1642e-03, 1.3377e-06, 1.7230e-05, 6.8453e-03, 5.5034e-05,\n","            4.8631e-04, 3.8980e-07, 8.9671e-04, 1.2829e-04, 7.4175e-03, 1.8872e-04,\n","            3.0450e-06, 4.0417e-12, 1.5019e-03, 1.0710e-03, 1.3015e-06, 5.5536e-05,\n","            5.2755e-07, 8.7277e-04, 5.3983e-05, 1.9709e-03, 1.0895e-06, 1.0446e-04,\n","            3.0519e-09, 5.8935e-07, 3.1054e-08, 1.9167e-07, 7.7812e-03, 7.9925e-04,\n","            4.1470e-05, 4.6036e-06, 3.8304e-07, 3.9409e-11, 3.4878e-04, 5.4547e-06,\n","            2.7682e-06, 5.1862e-05, 2.7919e-07, 2.1027e-05, 1.4838e-03, 8.9107e-04,\n","            4.0626e-06, 5.1215e-02, 3.8256e-05, 9.4898e-03],\n","           [6.4255e-07, 7.8077e-03, 2.8036e-07, 4.5573e-11, 1.9830e-03, 1.5957e-04,\n","            2.5098e-03, 1.3207e-04, 2.3185e-04, 7.3341e-07, 3.2703e-05, 1.7472e-11,\n","            1.3916e-02, 8.9790e-06, 2.2754e-02, 6.0471e-05, 4.7054e-07, 1.1505e-05,\n","            2.2261e-12, 7.4025e-04, 7.8833e-08, 7.8792e-06, 3.9083e-03, 8.1911e-05,\n","            4.8138e-05, 9.1633e-07, 3.3501e-03, 3.7605e-05, 1.7561e-05, 3.7520e-05,\n","            1.3554e-06, 3.6205e-12, 4.7842e-03, 1.5501e-03, 4.7380e-07, 4.8111e-05,\n","            6.4034e-06, 1.1555e-03, 3.9119e-06, 7.1046e-05, 1.7472e-06, 2.9914e-05,\n","            1.5043e-07, 5.1714e-07, 3.5156e-10, 6.1430e-06, 8.7850e-05, 1.6025e-03,\n","            8.6297e-04, 5.7991e-06, 7.0273e-09, 6.1648e-12, 2.0457e-04, 2.6903e-06,\n","            3.4044e-06, 7.0024e-04, 5.6408e-07, 4.8488e-04, 3.1577e-03, 7.8682e-06,\n","            3.9889e-10, 2.4513e-03, 1.7805e-05, 5.3801e-03],\n","           [1.4269e-06, 3.6771e-02, 9.8892e-07, 2.0051e-11, 8.7265e-03, 8.5060e-04,\n","            6.3232e-03, 6.8775e-06, 5.2362e-03, 2.9835e-07, 2.9288e-06, 6.8178e-10,\n","            6.2195e-04, 3.3733e-05, 9.9444e-03, 1.6501e-05, 9.1654e-07, 9.2091e-04,\n","            5.2817e-10, 1.8206e-03, 8.7164e-07, 4.8784e-05, 2.8822e-03, 2.5587e-05,\n","            2.3262e-04, 1.8991e-06, 4.4736e-04, 3.3568e-05, 5.8732e-03, 3.2457e-05,\n","            1.5998e-06, 6.3356e-11, 5.7092e-03, 1.2808e-03, 4.1765e-06, 1.6411e-04,\n","            1.1432e-06, 2.2348e-04, 6.6582e-05, 2.1943e-03, 8.4884e-07, 7.4100e-05,\n","            3.5835e-08, 9.4778e-07, 3.7182e-09, 1.8408e-06, 1.1706e-02, 3.0384e-03,\n","            1.7958e-04, 6.6098e-06, 4.9467e-07, 1.5446e-11, 2.0839e-03, 5.5780e-06,\n","            1.4193e-07, 4.0094e-05, 5.6041e-08, 2.7598e-05, 1.6959e-04, 9.5919e-04,\n","            2.9439e-08, 5.2284e-02, 5.1320e-05, 5.7261e-03],\n","           [4.1625e-04, 4.2051e-05, 5.4700e-09, 1.4879e-09, 1.0421e-04, 1.2794e-04,\n","            1.5600e-05, 8.6954e-03, 1.4465e-05, 2.0704e-03, 4.8886e-04, 1.1163e-09,\n","            1.4341e-05, 5.1021e-07, 2.6718e-04, 1.9896e-07, 5.2946e-09, 8.4582e-08,\n","            1.2403e-13, 4.5505e-05, 3.0362e-05, 1.1088e-05, 1.7325e-03, 8.0692e-03,\n","            7.2519e-06, 7.6417e-07, 7.4973e-06, 2.3673e-04, 4.1086e-06, 2.6119e-03,\n","            1.3405e-06, 4.0362e-13, 1.0976e-04, 8.1257e-04, 2.1087e-06, 3.1324e-03,\n","            1.9419e-03, 1.1094e-05, 2.5086e-06, 1.9946e-10, 1.7661e-03, 6.9780e-03,\n","            1.0980e-05, 1.7233e-10, 9.1616e-09, 1.6336e-07, 1.3581e-04, 1.3638e-05,\n","            2.4088e-04, 9.6812e-07, 2.4155e-08, 2.4116e-12, 1.6417e-04, 8.0564e-05,\n","            2.5517e-03, 6.6211e-06, 1.5982e-05, 2.2764e-03, 1.1054e-04, 1.1469e-06,\n","            2.2405e-10, 2.7225e-05, 4.9308e-03, 1.9209e-04],\n","           [5.6466e-06, 1.5338e-02, 1.4158e-05, 7.2859e-09, 1.4090e-03, 4.5535e-03,\n","            1.0595e-02, 1.7125e-05, 5.9509e-03, 3.7905e-06, 2.1735e-06, 7.7249e-09,\n","            2.3187e-02, 1.7052e-05, 5.4974e-03, 5.9746e-05, 2.5599e-06, 1.0815e-03,\n","            3.9910e-10, 3.2178e-03, 4.6206e-06, 8.5360e-06, 5.2850e-02, 6.4518e-05,\n","            2.7325e-04, 3.4358e-07, 4.9997e-03, 3.1662e-04, 1.9239e-03, 4.6526e-04,\n","            7.1790e-06, 3.6018e-11, 2.0726e-03, 6.6570e-04, 3.1052e-06, 3.0850e-04,\n","            1.3881e-06, 6.9630e-03, 9.7982e-05, 1.2355e-04, 1.0815e-05, 5.4414e-05,\n","            2.7384e-07, 1.1277e-05, 2.9957e-08, 8.7431e-07, 9.7215e-03, 9.0832e-03,\n","            1.0737e-04, 2.1133e-06, 4.5062e-07, 5.4854e-10, 4.0990e-03, 9.1126e-06,\n","            7.4580e-07, 1.4151e-04, 6.2107e-07, 4.5571e-05, 1.0556e-02, 1.0622e-04,\n","            7.1205e-07, 4.7365e-02, 1.0327e-04, 6.7154e-03],\n","           [7.1182e-03, 4.4806e-05, 5.9979e-06, 1.7806e-11, 5.0128e-05, 1.3013e-04,\n","            6.9394e-06, 1.7313e-03, 5.6896e-05, 2.7356e-03, 2.7371e-03, 9.1607e-12,\n","            3.1358e-06, 6.1193e-07, 1.0403e-04, 4.7643e-07, 2.4653e-10, 6.9675e-10,\n","            2.6109e-14, 3.5318e-04, 4.6047e-05, 6.2555e-06, 5.5248e-04, 6.2518e-03,\n","            9.5733e-05, 2.6446e-06, 1.0854e-06, 6.6910e-05, 1.5252e-07, 2.2405e-03,\n","            1.0586e-06, 2.3185e-10, 2.9950e-04, 5.9420e-04, 3.5322e-07, 5.5787e-04,\n","            2.8648e-03, 2.8777e-07, 3.9547e-06, 1.0861e-09, 1.6521e-02, 6.4159e-03,\n","            1.0804e-06, 1.0219e-10, 3.4062e-08, 1.0607e-07, 4.2221e-05, 2.9126e-06,\n","            1.1612e-03, 1.9817e-06, 1.0054e-08, 6.4135e-12, 4.1766e-05, 1.3015e-04,\n","            4.3025e-03, 2.2958e-06, 2.7353e-05, 4.8835e-03, 7.8257e-05, 1.1254e-06,\n","            7.0621e-11, 1.2740e-06, 4.3960e-03, 1.3523e-04],\n","           [9.8865e-05, 2.0015e-04, 5.3322e-06, 1.8943e-10, 1.2876e-03, 1.8928e-03,\n","            2.1790e-04, 3.3840e-05, 1.4497e-04, 4.8497e-05, 3.5332e-06, 3.2098e-09,\n","            2.3242e-04, 3.2144e-06, 2.0052e-03, 2.0971e-06, 3.9078e-07, 3.9867e-06,\n","            2.0389e-11, 9.5952e-05, 2.8494e-05, 6.8358e-05, 6.5832e-04, 8.2147e-05,\n","            1.5469e-05, 6.7815e-07, 3.4002e-05, 4.6589e-04, 6.1098e-05, 1.2986e-03,\n","            8.3070e-08, 1.7857e-11, 1.7813e-04, 2.7292e-04, 3.7460e-05, 1.5096e-03,\n","            1.0621e-04, 1.3994e-04, 2.8869e-05, 7.2566e-06, 9.6796e-05, 6.1626e-04,\n","            9.9541e-09, 3.0098e-08, 7.4509e-09, 2.4011e-07, 4.1844e-04, 6.4575e-05,\n","            4.2362e-05, 7.4279e-07, 5.0680e-08, 3.5657e-10, 2.6097e-05, 6.5143e-06,\n","            8.6970e-05, 5.3923e-05, 5.2308e-06, 3.9385e-04, 7.8569e-04, 5.0006e-06,\n","            1.7194e-08, 5.8501e-04, 1.2231e-03, 1.1158e-04],\n","           [6.8365e-03, 1.0006e-05, 5.9620e-06, 2.8011e-10, 1.2106e-05, 8.0499e-05,\n","            6.6918e-06, 9.2113e-03, 6.1173e-05, 9.6112e-04, 3.1149e-03, 1.0563e-09,\n","            1.0038e-06, 3.3868e-07, 2.4700e-05, 4.7983e-07, 4.0735e-09, 4.0436e-09,\n","            4.5279e-14, 3.9166e-04, 1.0059e-04, 8.4602e-06, 8.7617e-04, 7.0433e-03,\n","            9.5739e-05, 1.7575e-06, 2.9979e-06, 4.3458e-05, 3.7536e-07, 5.1371e-04,\n","            1.9910e-07, 2.1460e-10, 1.7592e-04, 3.6368e-05, 6.0347e-07, 2.9588e-03,\n","            8.5333e-04, 1.4968e-06, 5.2371e-06, 1.0188e-08, 1.6931e-02, 4.6713e-04,\n","            1.1991e-05, 2.2286e-10, 3.0865e-08, 6.1177e-08, 5.0353e-06, 1.3004e-05,\n","            1.2105e-03, 3.2190e-06, 5.4871e-11, 6.7748e-12, 2.0190e-04, 1.9602e-04,\n","            2.0639e-03, 5.7634e-07, 7.8389e-06, 2.1620e-03, 7.1821e-06, 2.2378e-07,\n","            4.5457e-10, 2.4386e-06, 3.1564e-04, 7.1040e-06]], device='cuda:0')},\n","  7: {'step': tensor(4690.),\n","   'exp_avg': tensor([ 8.4582e-03, -6.7572e-05,  4.2825e-03, -4.6682e-03,  3.4197e-03,\n","            6.8243e-04, -1.0722e-02,  3.1026e-04, -5.9613e-04, -1.0991e-03],\n","          device='cuda:0'),\n","   'exp_avg_sq': tensor([4.8464e-04, 6.0112e-05, 5.6405e-04, 3.2783e-04, 6.3757e-04, 1.7120e-04,\n","           8.4464e-04, 2.3957e-04, 8.9078e-05, 1.6291e-04], device='cuda:0')}},\n"," 'param_groups': [{'lr': 0.003,\n","   'betas': (0.9, 0.999),\n","   'eps': 1e-08,\n","   'weight_decay': 0,\n","   'amsgrad': False,\n","   'maximize': False,\n","   'foreach': None,\n","   'capturable': False,\n","   'differentiable': False,\n","   'fused': None,\n","   'params': [0, 1, 2, 3, 4, 5, 6, 7]}]}"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["## Dictionary로 저장하기"],"metadata":{"id":"JBmsmBKhG_DA"}},{"cell_type":"code","source":["checkpoint = {'model_state_dict': model.state_dict(),\n","              'optimizer_state_dict': optimizer.state_dict()}\n","\n","torch.save(checkpoint, 'checkpoint.pth')"],"metadata":{"trusted":true,"id":"4JBmybAcG_DA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(checkpoint['model_state_dict'])"],"metadata":{"trusted":true,"id":"VYGtb4PQG_DA","executionInfo":{"status":"ok","timestamp":1686577652877,"user_tz":-540,"elapsed":33,"user":{"displayName":"전찬수","userId":"10602042438598641223"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e8c232ae-d127-492e-b051-1cfb2691d82e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["* 한가지 주의해야할 부분이 있습니다. 쉽게 생각해볼 수 있는데, 내가 저장된 state_dict를 적용하고자 하는 모델 구조를 항상 있어야 합니다\n"],"metadata":{"id":"DBcfOY3LG_DA"}},{"cell_type":"code","source":["torch.save(model, 'model_save.pt')"],"metadata":{"trusted":true,"id":"v_aKMPc8G_DA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_load = torch.load('model_save.pt')"],"metadata":{"trusted":true,"id":"5qsmCy8rG_DB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_load"],"metadata":{"id":"DHmpIXR_hx-z","executionInfo":{"status":"ok","timestamp":1686577652878,"user_tz":-540,"elapsed":24,"user":{"displayName":"전찬수","userId":"10602042438598641223"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"99b52a40-6a4d-42b2-c194-fb2da1295aef"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Classifier(\n","  (fc1): Linear(in_features=784, out_features=256, bias=True)\n","  (fc2): Linear(in_features=256, out_features=128, bias=True)\n","  (fc3): Linear(in_features=128, out_features=64, bias=True)\n","  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["# Part 2: Transfer Learning\n","\n","* Part 2에서는 이미 training이 잘된 네트워크를 불러와서 적용하는 방법을 실습하도록 하겠습니다\n","* '잘된 네트워크'는 여기서 [ImageNet](http://www.image-net.org/) [available from torchvision](http://pytorch.org/docs/0.3.0/torchvision/models.html)에서 학습된 모델을 활용하도록 하겠습니다\n","* `ImageNet`은 14,000,000개의 image파일을 20,000개의 class로 분류되어있는 database 운영\n","  * 예를 들면 `딸기`, `풍선`등의 분류가 있으면, 각 분류별로 수백개의 image가 존재합니다\n","  * 각 이미지들은 수작업으로 labeling 되어있고, bounding box까지 표시가 되어 있습니다\n","  * 2010년 이후로 대회를 진행 ImageNet Large Scale Visual Recognition Challenge (ILSVRC)\n","    * 수천개의 class를 추려서 대회 진행\n","  * AlexNet과 그 이후: top-5 분류에서 15.3%로 혁신적 결과를 시작으로 deep learning 시대를 견인\n","    * GPU의 사용!\n","* 우리는 실제 사용하고자 하는 network를 직접 training 하는 경우보다, imagenet 등에서 매우 잘 동작하는 network을 적용하여, 부분적 학습을 통해서 사용하게 됩니다\n","* 본 실습에서는 imagenet에서 모델을 받아서 적용하는 방법을 알아보죠~\n"],"metadata":{"id":"3MC1BL6KG_DB"}},{"cell_type":"markdown","source":["### Data 준비\n","* 위 Imagenet에서 사용된 자료는 다양한 class를 분류하는 작업을 수행합니다\n","* 이를 우리가 지난 시간에 받았던 `dog`, `cat`분류 문제에 적용하는 방법을 알아보도록 하겠습니다\n","* dataset은 다음 url에서 download 혹은 `+Add data`를 통해서 가져옵니다\n","\n","https://www.kaggle.com/datasets/dlsunghlim/hallym-deep-learning-dogcat-data"],"metadata":{"id":"iEBq4hdsG_DB"}},{"cell_type":"code","source":["!pip install kaggle\n","from google.colab import files\n","files.upload()"],"metadata":{"id":"iLaFEmXzjXf0","executionInfo":{"status":"error","timestamp":1686577693492,"user_tz":-540,"elapsed":40636,"user":{"displayName":"전찬수","userId":"10602042438598641223"}},"colab":{"base_uri":"https://localhost:8080/","height":628},"outputId":"528bbb5a-26c4-4505-8775-90ca67cec4e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.13)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2022.12.7)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.15)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-5bf4ee2e-bc94-43ed-966e-fcd163e5102d\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-5bf4ee2e-bc94-43ed-966e-fcd163e5102d\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-8090cb07c344>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install kaggle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m   \"\"\"\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    154\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    155\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["ls -1ha kaggle.json"],"metadata":{"id":"d3vQAoWnje3p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","# Permission Warning이 발생하지 않도록 해줍니다.\n","!chmod 600 ~/.kaggle/kaggle.json\n"],"metadata":{"id":"IxbMR-t-joHT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! kaggle datasets download -d dlsunghlim/hallym-deep-learning-dogcat-data"],"metadata":{"id":"UUDj7nF4kTP-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"id":"ThkOgSIzkdj-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"V_HxpTNiyf8D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"b6UaccsWyhCp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kXaq3w5ByiLJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip hallym-deep-learning-dogcat-data.zip"],"metadata":{"id":"qUwAVIQVkfm8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Loading Densenet121\n","* 본 실습을 위해서 우리는 [DenseNet](http://pytorch.org/docs/0.3.0/torchvision/models.html#id5)을 활용하고자 합니다. 아래 불러오기와 구조를 살펴보죠"],"metadata":{"id":"TyEzwiX4G_DB"}},{"cell_type":"code","source":["from torchvision import models\n","model = models.densenet121(pretrained=True)\n","model"],"metadata":{"scrolled":true,"trusted":true,"id":"-2czWjQ9G_DB","executionInfo":{"status":"ok","timestamp":1686577548002,"user_tz":-540,"elapsed":5125,"user":{"displayName":"전찬수","userId":"10602042438598641223"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e65f275f-39bb-4cab-8067-daf0819f0013"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n","100%|██████████| 30.8M/30.8M [00:00<00:00, 60.4MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["DenseNet(\n","  (features): Sequential(\n","    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu0): ReLU(inplace=True)\n","    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (denseblock1): _DenseBlock(\n","      (denselayer1): _DenseLayer(\n","        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer2): _DenseLayer(\n","        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer3): _DenseLayer(\n","        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer4): _DenseLayer(\n","        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer5): _DenseLayer(\n","        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer6): _DenseLayer(\n","        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","    )\n","    (transition1): _Transition(\n","      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    )\n","    (denseblock2): _DenseBlock(\n","      (denselayer1): _DenseLayer(\n","        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer2): _DenseLayer(\n","        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer3): _DenseLayer(\n","        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer4): _DenseLayer(\n","        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer5): _DenseLayer(\n","        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer6): _DenseLayer(\n","        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer7): _DenseLayer(\n","        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer8): _DenseLayer(\n","        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer9): _DenseLayer(\n","        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer10): _DenseLayer(\n","        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer11): _DenseLayer(\n","        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer12): _DenseLayer(\n","        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","    )\n","    (transition2): _Transition(\n","      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    )\n","    (denseblock3): _DenseBlock(\n","      (denselayer1): _DenseLayer(\n","        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer2): _DenseLayer(\n","        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer3): _DenseLayer(\n","        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer4): _DenseLayer(\n","        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer5): _DenseLayer(\n","        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer6): _DenseLayer(\n","        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer7): _DenseLayer(\n","        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer8): _DenseLayer(\n","        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer9): _DenseLayer(\n","        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer10): _DenseLayer(\n","        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer11): _DenseLayer(\n","        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer12): _DenseLayer(\n","        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer13): _DenseLayer(\n","        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer14): _DenseLayer(\n","        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer15): _DenseLayer(\n","        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer16): _DenseLayer(\n","        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer17): _DenseLayer(\n","        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer18): _DenseLayer(\n","        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer19): _DenseLayer(\n","        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer20): _DenseLayer(\n","        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer21): _DenseLayer(\n","        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer22): _DenseLayer(\n","        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer23): _DenseLayer(\n","        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer24): _DenseLayer(\n","        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","    )\n","    (transition3): _Transition(\n","      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    )\n","    (denseblock4): _DenseBlock(\n","      (denselayer1): _DenseLayer(\n","        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer2): _DenseLayer(\n","        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer3): _DenseLayer(\n","        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer4): _DenseLayer(\n","        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer5): _DenseLayer(\n","        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer6): _DenseLayer(\n","        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer7): _DenseLayer(\n","        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer8): _DenseLayer(\n","        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer9): _DenseLayer(\n","        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer10): _DenseLayer(\n","        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer11): _DenseLayer(\n","        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer12): _DenseLayer(\n","        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer13): _DenseLayer(\n","        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer14): _DenseLayer(\n","        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer15): _DenseLayer(\n","        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer16): _DenseLayer(\n","        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","    )\n","    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",")"]},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","source":["### densenet121의 구조\n","\n","* 위에서 불러온 `densenet121`의 구조를 살펴보면 크게 두가지로 나눠집니다\n","  * (features) 부분과\n","  * (classifier) 부분으로 나눠집니다\n","* 위에서 (features) 부분은 매우 복잡한 layer들로 구성되어 있으며, 특별히, convolutional network으로 구성되어 있습니다. (이부분은 다음 시간부터 배우게 됩니다)\n","* 여기서 (features)에 해당하는 부분은 그대로 활용할 것이며, classifier에 대당하는 부분만 바꿔서 사용하고자 합니다\n","* 여기서 유념해야하는 부분은 classifier의 `output_feature=1000` 부분입니다\n","  * (classifier)는 fully-connected layer로\n","    * `(classifier): Linear(in_features=1024, out_features=1000)` 임\n","  * `output_feature=1000`는 분류는 1000가지로 수행하고 있는 네트워크라는 뜻입니다\n","  * 우리는 이부분을 2가지 dog, cat 중 한가지로 수행하도록 변경하고자 합니다\n","\n","* 또한, densenet121은 입력 image가 224x224로 받습니다\n","* Densenet121에서 정규화한 값 또한 맞춰줘야 합니다 Densenet121의 경우는\n","  * mean `[0.485, 0.456, 0.406]` and the standard deviations `[0.229, 0.224, 0.225]로 학습되었습니다\n","* 위 정보에 맞춰서 우리 학습하고자 하는 IMAGE를 불러옵니다"],"metadata":{"id":"pOisTMIXG_DC"}},{"cell_type":"code","source":["data_dir = '/content'\n","\n","# TODO: Define transforms for the training data and testing data\n","train_transforms = transforms.Compose([transforms.RandomRotation(30),\n","                                       transforms.RandomResizedCrop(224),\n","                                       transforms.RandomHorizontalFlip(),\n","                                       transforms.ToTensor(),\n","                                       transforms.Normalize([0.485, 0.456, 0.406],\n","                                                            [0.229, 0.224, 0.225])])\n","\n","test_transforms = transforms.Compose([transforms.Resize(255),\n","                                      transforms.CenterCrop(224),\n","                                      transforms.ToTensor(),\n","                                      transforms.Normalize([0.485, 0.456, 0.406],\n","                                                           [0.229, 0.224, 0.225])])\n","\n","# Pass transforms in here, then run the next cell to see how the transforms look\n","train_data = datasets.ImageFolder(data_dir +'/train', transform=train_transforms)\n","test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n","\n","trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n","testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"],"metadata":{"trusted":true,"id":"PRfEJqE9G_DC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Transfer learning\n","\n","* 위에서 가져온 densenet121의 네트워크에서 우리는 `classifier` 부분을 다시 우리 목적에 맞게 설계하고 다시 학습하고자 합니다 (이유는 영상에서 설명하도록 하겠습니다)\n","\n","* 이때, densenet121에서 `feature` 부분은 다시 training 하지 않고 그대로 유지합니다. 이를 위해서 `feature`부분은 동결 (freeze)하고, 즉 backprop을 수행하지 않고, `classifier`부분만 수행합니다.\n","\n","* 동결을 위해서 모든 `model.paramters()`의 `requires_grad = False` 로 바꿔줍니다\n","* 이후 classifier 부분을 덮어서 새로 구현하면, 이부분은 자동으로 gradient가 활성화 된 상태로 만들어지겠죠?"],"metadata":{"id":"8AHdcnbvG_DC"}},{"cell_type":"code","source":["from collections import OrderedDict"],"metadata":{"trusted":true,"id":"SCpHiEvvG_DC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Backprop을 수행하지 않도록 parameter들을 동결시킴\n","for param in model.parameters():\n","    param.requires_grad = False  #gradients업데이터X -> 더이상 학습X\n","\n","classifier = nn.Sequential(OrderedDict([\n","                          ('fc1', nn.Linear(1024, 500)), #1024에서 바로 2로 내려가는 것은 과하기때문에 layer를 중간에 하나 더 줌\n","                          ('relu', nn.ReLU()),\n","                          ('fc2', nn.Linear(500, 2))\n","                          ]))\n","\n","model.classifier = classifier #densenet의 마지막에 classifier layer인 linear layer가 있기때문에 classifier를 변경"],"metadata":{"trusted":true,"id":"AE7DE08SG_DC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model"],"metadata":{"id":"5ujtvEmVnvwh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Retraining the network"],"metadata":{"id":"lkpbQB1YG_DD"}},{"cell_type":"code","source":["model = models.densenet121(pretrained=True)\n","\n","# Freeze parameters so we don't backprop through them\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","model.classifier = nn.Sequential(nn.Linear(1024, 256),\n","                                 nn.ReLU(),\n","                                 nn.Dropout(0.2),\n","                                 nn.Linear(256, 2)\n","                                 )\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","# Only train the classifier parameters, feature parameters are frozen\n","optimizer = optim.Adam(model.classifier.parameters(), lr=0.003)\n","\n","model.to(device)"],"metadata":{"trusted":true,"id":"lsCyR9_7G_DD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 3\n","\n","for epoch in range(epochs):\n","    running_loss = 0\n","    for inputs, labels in trainloader:\n","\n","        # Move input and label tensors to the default device\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        logits = model.forward(inputs)\n","        loss = criterion(logits, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","\n","    test_loss = 0\n","    accuracy = 0\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for inputs, labels in testloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            logits = model.forward(inputs)\n","            batch_loss = criterion(logits, labels)\n","\n","            test_loss += batch_loss.item()\n","\n","            # Calculate accuracy\n","            ps = F.softmax(logits, dim=1)\n","            top_p, top_class = ps.topk(1, dim=1)\n","            equals = top_class == labels.view(*top_class.shape)\n","            accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n","    model.train()\n","\n","\n","    print(f\"Epoch {epoch+1}/{epochs}.. \"\n","          f\"Train loss: {running_loss/len(testloader):.3f}.. \"\n","          f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n","          f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n","\n","\n","########################################################"],"metadata":{"trusted":true,"id":"Gojkx2G-G_Da"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Problem 1\n","pytorch 에서 `VGG16` network을 받아서 3 epoch 동안 transfer learning 수행\n","\n","1) Training set을 training set과 validation set으로 나눠서 dataloader 준비 할 것\n","\n","2) epoch 별 traning loss, validation loss 그래프를 출력\n","\n","3) 최종 test accuracy를 출력하세요"],"metadata":{"id":"svpFNUjwG_Da"}},{"cell_type":"code","source":["model = models.vgg16(pretrained=True)"],"metadata":{"trusted":true,"id":"QTEuBjiNG_Da"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = models.vgg16(pretrained=True)\n","\n","# Freeze parameters so we don't backprop through them\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","model.classifier = nn.Sequential(nn.Linear(25088, 4096),\n","                                 nn.ReLU(),\n","                                 nn.Dropout(0.5),\n","                                 nn.Linear(4096, 2048),\n","                                 nn.ReLU(),\n","                                 nn.Dropout(0.5),\n","                                 nn.Linear(2048,256),\n","                                 nn.ReLU(),\n","                                 nn.Dropout(0.5),\n","                                 nn.Linear(256,2)\n","                                 )\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","# Only train the classifier parameters, feature parameters are frozen\n","optimizer = optim.Adam(model.classifier.parameters(), lr=0.003)\n","\n","model.to(device)"],"metadata":{"trusted":true,"id":"0B-jkMzoG_Da"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install split_folders\n","import splitfolders\n","\n","data_dir = '/content'\n","\n","train_transforms = transforms.Compose([transforms.RandomRotation(30),\n","                                       transforms.RandomResizedCrop(224),\n","                                       transforms.RandomHorizontalFlip(),\n","                                       transforms.ToTensor(),\n","                                       transforms.Normalize([0.485, 0.456, 0.406],\n","                                                            [0.229, 0.224, 0.225])])\n","\n","test_transforms = transforms.Compose([transforms.Resize(255),\n","                                      transforms.CenterCrop(224),\n","                                      transforms.ToTensor(),\n","                                      transforms.Normalize([0.485, 0.456, 0.406],\n","                                                           [0.229, 0.224, 0.225])])\n","\n","splitfolders.ratio(\"train\", output=\"train_spt\", seed=135, ratio=(.7, .3))\n","\n","\n","\n"],"metadata":{"id":"LprcvfD6G_Db"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data = datasets.ImageFolder(data_dir +'/train_spt/train', transform=train_transforms)\n","validation_data = datasets.ImageFolder(data_dir + '/train_spt/val',transform=train_transforms)\n","test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n","\n","\n","\n","trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n","validationloader = torch.utils.data.DataLoader(train_data,batch_size=64, shuffle = True)\n","testloader = torch.utils.data.DataLoader(test_data, batch_size=64)\n","\n"],"metadata":{"id":"t_WUe3mBKaxv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BbBHxsf-Lj3l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","\n","epochs = 3\n","\n","for epoch in range(epochs):\n","    running_loss = 0\n","    for inputs, labels in trainloader:\n","\n","        # Move input and label tensors to the default device\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        logits = model.forward(inputs)\n","        loss = criterion(logits, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","\n","    test_loss = 0\n","    accuracy = 0\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for inputs, labels in validationloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            logits = model.forward(inputs)\n","            batch_loss = criterion(logits, labels)\n","\n","            test_loss += batch_loss.item()\n","\n","            # Calculate accuracy\n","            ps = F.softmax(logits, dim=1)\n","            top_p, top_class = ps.topk(1, dim=1)\n","            equals = top_class == labels.view(*top_class.shape)\n","            accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n","    model.train()\n","\n","    print(f\"Epoch {epoch+1}/{epochs}.. \"\n","          f\"Train loss: {running_loss/len(validationloader):.3f}.. \"\n","          f\"Test loss: {test_loss/len(validationloader):.3f}.. \"\n","          f\"Test accuracy: {accuracy/len(validationloader):.3f}\")\n","\n","\n","\n","########################################################"],"metadata":{"id":"agpTcPRgIIma"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 3\n","\n","for epoch in range(epochs):\n","    running_loss = 0\n","    for inputs, labels in trainloader:\n","\n","        # Move input and label tensors to the default device\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        logits = model.forward(inputs)\n","        loss = criterion(logits, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","\n","    test_loss = 0\n","    accuracy = 0\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for inputs, labels in testloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            logits = model.forward(inputs)\n","            batch_loss = criterion(logits, labels)\n","\n","            test_loss += batch_loss.item()\n","\n","            # Calculate accuracy\n","            ps = F.softmax(logits, dim=1)\n","            top_p, top_class = ps.topk(1, dim=1)\n","            equals = top_class == labels.view(*top_class.shape)\n","            accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n","    model.train()\n","\n","\n","    print(f\"Epoch {epoch+1}/{epochs}.. \"\n","          f\"Train loss: {running_loss/len(testloader):.3f}.. \"\n","          f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n","          f\"Test accuracy: {accuracy/len(testloader):.3f}\")"],"metadata":{"id":"LC7xaBrVT-9O"},"execution_count":null,"outputs":[]}]}